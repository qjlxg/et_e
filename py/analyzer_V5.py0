import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- V5.0 ç­–ç•¥æ‰€éœ€é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_MONTH_DRAWDOWN = 0.06 # V5.0 éœ‡è¡å¸‚æ ¸å¿ƒè§¦å‘ (å›æ’¤ >= 5%, æ­¤å¤„ä½¿ç”¨ 6% è¿‘ä¼¼ç­›é€‰)
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15 # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (15%)
MIN_DAILY_DROP_PERCENT = 0.03 # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report_v5_final_filter'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 # ç½‘æ ¼çº§ï¼šRSI(14) æå€¼è¶…å–
STRONG_RSI_THRESHOLD_P2 = 35.0 # å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± 
SHORT_TERM_RSI_EXTREME = 20.0 # RSI(6)çš„æå€¼è¶…å–é˜ˆå€¼
TREND_HEALTH_THRESHOLD = 0.95 # MA50/MA250 å¥åº·åº¦é˜ˆå€¼
MIN_BUY_SIGNAL_SCORE = 4.0 # ã€æ–°å¢ã€‘å¯è¯•ä»“ç»„çš„æœ€ä½ä¿¡å·åˆ†æ•°è¦æ±‚ (åªå…è®¸ ç½‘æ ¼çº§/é«˜å¸/é˜²å¾¡)

# --- è®¾ç½®æ—¥å¿— (å‡½æ•°é…ç½® 1/13) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- éªŒè¯æ•°æ® (å‡½æ•°é…ç½® 2/13) ---
def validate_fund_data(df, fund_code):
    """éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    if df.empty: return False, "æ•°æ®ä¸ºç©º"
    if 'value' not in df.columns: return False, "ç¼ºå°‘å‡€å€¼åˆ—"
    if len(df) < 60: return False, f"æ•°æ®ä¸è¶³60æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
    if (df['value'] <= 0).any(): return False, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
    return True, "æ•°æ®æœ‰æ•ˆ"

# --- å¸ƒæ—å¸¦è®¡ç®— (å‡½æ•°é…ç½® 3/13) ---
def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        range_band = latest_upper - latest_lower
        if range_band == 0:
            return "è½¨é“ä¸­é—´" 
            
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (å‡½æ•°é…ç½® 4/13) ---
def calculate_technical_indicators(df):
    """
    è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ (RSI(14), RSI(6), MACD, MA, è¶‹åŠ¿ç­‰)
    """
    df_asc = df.copy()

    try:
        if 'value' not in df_asc.columns or len(df_asc) < 60:
            return {
                'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 
                'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³', 'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 
                'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
            }

        delta = df_asc['value'].diff()

        # 1. RSI (14) & (6)
        for window in [14, 6]:
            gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()
            rs = gain / loss.replace(0, np.nan) 
            df_asc[f'RSI_{window}'] = 100 - (100 / (1 + rs))

        rsi_14_latest = df_asc['RSI_14'].iloc[-1]
        rsi_6_latest = df_asc['RSI_6'].iloc[-1]
        
        # 2. MACD
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            is_golden_cross = macd_latest > signal_latest and macd_prev < signal_prev
            
            if is_golden_cross:
                if macd_latest > 0: macd_signal = 'å¼ºåŠ¿é‡‘å‰'
                elif macd_latest < 0: macd_signal = 'å¼±åŠ¿é‡‘å‰'
                else: macd_signal = 'é‡‘å‰'
        
        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean() 
        
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]
        
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan
        
        if len(df_asc) < 250:
            net_to_ma250 = np.nan
            ma50_to_ma250 = np.nan
            trend_direction = 'æ•°æ®ä¸è¶³'
        else:
            net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            
            trend_direction = 'æ•°æ®ä¸è¶³'
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(20).dropna()
            if len(recent_ratio) >= 5:
                # æ‹ŸåˆMA50/MA250æ¯”å€¼çš„æ–œç‡
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                if slope > 0.001: trend_direction = 'å‘ä¸Š'
                elif slope < -0.001: trend_direction = 'å‘ä¸‹'
                else: trend_direction = 'å¹³ç¨³'
        
        # 4. å½“æ—¥æ¶¨è·Œå¹…
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                daily_drop = (value_latest - value_t_minus_1) / value_t_minus_1
                
        # 5. å¸ƒæ—å¸¦ä½ç½®
        bollinger_position = calculate_bollinger_bands(df_asc['value'])

        return {
            'RSI(14)': round(rsi_14_latest, 2) if not math.isnan(rsi_14_latest) else np.nan, 
            'RSI(6)': round(rsi_6_latest, 2) if not math.isnan(rsi_6_latest) else np.nan,     
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_position, 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 
            'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯', 'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯',
            'æœ€æ–°å‡€å€¼': np.nan, 'å½“æ—¥è·Œå¹…': np.nan
        }

# --- è¿ç»­ä¸‹è·Œè®¡ç®— (å‡½æ•°é…ç½® 5/13) ---
def calculate_consecutive_drops(series):
    try:
        if series.empty or len(series) < 2: return 0
        drops = (series.diff() < 0).values
        max_drop_days = 0
        current_drop_days = 0
        
        for is_dropped in drops:
            if is_dropped: 
                current_drop_days += 1
                max_drop_days = max(max_drop_days, current_drop_days)
            else: 
                current_drop_days = 0
        
        return max_drop_days
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

# --- æœ€å¤§å›æ’¤è®¡ç®— (å‡½æ•°é…ç½® 6/13) ---
def calculate_max_drawdown(series):
    try:
        if series.empty: return 0.0
        rolling_max = series.cummax()
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

# --- V5.0 è¡ŒåŠ¨ä¿¡å·ç”Ÿæˆ (å‡½æ•°é…ç½® 7/13) ---
def generate_v5_action_signal(row):
    """
    æ ¹æ® V5.0 ç­–ç•¥çš„æŠ€æœ¯è¦æ±‚ï¼Œç”Ÿæˆè¯•ä»“ä¿¡å·ã€‚
    """
    rsi_14_val = row.get('RSI(14)', np.nan)
    rsi_6_val = row.get('RSI(6)', np.nan)
    macd_signal = row.get('MACDä¿¡å·', '')
    bollinger_position = row.get('å¸ƒæ—å¸¦ä½ç½®', '')
    mdd_recent_month = row.get('æœ€å¤§å›æ’¤', 0.0)
    daily_drop_val = row.get('å½“æ—¥è·Œå¹…', 0.0)
    
    signals = []

    # --- V5.0 ç½‘æ ¼çº§ / æå€¼è¶…å–ä¿¡å· (æœ€é«˜ä¼˜å…ˆçº§ï¼Œç‹¬ç«‹äºå§¿æ€) ---
    if not pd.isna(rsi_14_val) and rsi_14_val <= EXTREME_RSI_THRESHOLD_P1:
        rsi_display = f"RSI14:{rsi_14_val:.1f}"
        if rsi_6_val <= SHORT_TERM_RSI_EXTREME:
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯({rsi_display})")
        elif daily_drop_val <= -MIN_DAILY_DROP_PERCENT:
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼+ææ…Œ({rsi_display})")
        else:
            signals.append(f"ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼({rsi_display})")

    # --- V5.0 æ¸¸å‡»å§¿æ€ (éœ‡è¡å¸‚) ä¿¡å· ---
    if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
        if bollinger_position in ["**ä¸‹è½¨ä¸‹æ–¹**", "ä¸‹è½¨é™„è¿‘"]:
            signals.append("ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘è§¦åŠBOLLä¸‹è½¨")
        elif mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN:
            signals.append("ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘é«˜å¼¹æ€§å›æ’¤è¾¾æ ‡")
        elif not signals:
            signals.append("ã€éœ‡è¡-å…³æ³¨ã€‘åŸºç¡€å›æ’¤è¾¾æ ‡")

    # --- V5.0 é˜²å¾¡å§¿æ€ (ç†Šå¸‚) ä¿¡å· ---
    if macd_signal == 'å¼±åŠ¿é‡‘å‰':
        signals.append("ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘MACDå¼±é‡‘å‰")
        
    # --- V5.0 è¿›æ”»å§¿æ€ (ç‰›å¸‚) è¿‡æ»¤å™¨æ£€æŸ¥ ---
    if not pd.isna(rsi_14_val) and rsi_14_val > 70.0:
        signals.append("ğŸš«ã€ç‰›å¸‚è¿‡æ»¤å™¨ã€‘RSI(14)>70")
        
    if not signals:
        return 'ç­‰å¾…ä¿¡å· (æœªè¾¾åŸºç¡€å›æ’¤)'
        
    return ' | '.join(signals)

# --- éå†å¹¶åˆ†ææ‰€æœ‰åŸºé‡‘ (å‡½æ•°é…ç½® 8/13) ---
def analyze_all_funds():
    """éå† FUND_DATA_DIR ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶å¹¶åˆ†æ"""
    fund_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
    results = []
    
    if not fund_files:
        logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°ä»»ä½•åŸºé‡‘æ•°æ®æ–‡ä»¶ã€‚")
        return results

    for filepath in fund_files:
        fund_result = analyze_single_fund(filepath)
        if fund_result:
            results.append(fund_result)
            
    logging.info(f"æ‰€æœ‰åŸºé‡‘åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªåŸºé‡‘ç¬¦åˆæŠ¥å‘Šæ¡ä»¶ã€‚")
    return results

# --- å•åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 9/13) ---
def analyze_single_fund(filepath):
    fund_code = os.path.splitext(os.path.basename(filepath))[0]
    df = pd.DataFrame()

    try:
        # å°è¯•ä½¿ç”¨ UTF-8, å¤±è´¥åå°è¯• GBK
        try:
            df = pd.read_csv(filepath)
        except UnicodeDecodeError:
            df = pd.read_csv(filepath, encoding='gbk')
        
        if 'date' not in df.columns or 'net_value' not in df.columns:
            if 'Date' in df.columns and 'NetValue' in df.columns:
                 df = df.rename(columns={'Date': 'date', 'NetValue': 'net_value'})
            else:
                return None
            
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        
        is_valid, msg = validate_fund_data(df, fund_code)
        if not is_valid: 
            return None
        
        df_recent_month = df['value'].tail(30)
        
        mdd_recent_month = calculate_max_drawdown(df_recent_month)
        
        tech_indicators = calculate_technical_indicators(df)
        
        row_data = {**tech_indicators, 'æœ€å¤§å›æ’¤': mdd_recent_month, 'å½“æ—¥è·Œå¹…': tech_indicators['å½“æ—¥è·Œå¹…']}
        
        action_prompt = generate_v5_action_signal(row_data)
        
        if not pd.isna(tech_indicators['æœ€æ–°å‡€å€¼']):
             return {
                'åŸºé‡‘ä»£ç ': fund_code,
                'æœ€å¤§å›æ’¤': mdd_recent_month,
                'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df['value'].tail(30)),
                'è¿‘ä¸€å‘¨è¿è·Œ': calculate_consecutive_drops(df['value'].tail(5)),
                **tech_indicators,
                'è¡ŒåŠ¨æç¤º': action_prompt
            }
        return None
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return None

# --- æŠ€æœ¯å€¼æ ¼å¼åŒ– (å‡½æ•°é…ç½® 10/13) ---
def format_technical_value(value, format_type='percent'):
    if pd.isna(value): return '---'
    
    if format_type == 'report_daily_drop':
        if value < 0:
            return f"**{value:.2%}**"
        elif value > 0:
            return f"{value:.2%}" 
        else:
            return "0.00%"
            
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

# --- è¡¨æ ¼è¡Œæ ¼å¼åŒ– (å‡½æ•°é…ç½® 11/13) ---
def format_table_row(index, row, table_part=1):
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    trial_price = latest_value * (1 - 0.03) # é¢„ä¼°è·Œ3%æ—¶çš„è¯•æ°´ä»·æ ¼
    
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio = row.get('MA50/MA250')
    ma_ratio_display = format_technical_value(ma_ratio, 'decimal2')
    
    # è¶‹åŠ¿é£é™©è­¦å‘Š
    is_data_insufficient = pd.isna(ma_ratio) or trend_display == 'æ•°æ®ä¸è¶³'
    
    if is_data_insufficient:
        trend_status = "---"
    elif trend_display == 'å‘ä¸‹' or (not pd.isna(ma_ratio) and ma_ratio < TREND_HEALTH_THRESHOLD): 
        trend_status = f"âš ï¸ **{trend_display}** ({ma_ratio_display})"
    else:
        trend_status = f"**{trend_display}** ({ma_ratio_display})"
        
    daily_drop_display = format_technical_value(row['å½“æ—¥è·Œå¹…'], 'report_daily_drop')


    if table_part == 1:
        # è¡¨æ ¼ 1 (7åˆ—): æ’å, åŸºé‡‘ä»£ç , æœ€å¤§å›æ’¤ (1M), å½“æ—¥æ¶¨è·Œå¹…, RSI(14), RSI(6), è¡ŒåŠ¨æç¤º
        # RSIå€¼å¦‚æœæå€¼è¶…å–ï¼Œå­—ä½“åŠ ç²—
        rsi14_display = f"**{row['RSI(14)']:.2f}**" if not pd.isna(row['RSI(14)']) and row['RSI(14)'] <= STRONG_RSI_THRESHOLD_P2 else f"{row['RSI(14)']:.2f}"
        rsi6_display = f"**{row['RSI(6)']:.2f}**" if not pd.isna(row['RSI(6)']) and row['RSI(6)'] <= SHORT_TERM_RSI_EXTREME else f"{row['RSI(6)']:.2f}"
        
        return (
            f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
            f"{daily_drop_display} | {rsi14_display} | {rsi6_display} | **{row['è¡ŒåŠ¨æç¤º']}** |\n"
        )
    else:
        # è¡¨æ ¼ 2 (8åˆ—): åŸºé‡‘ä»£ç , MACDä¿¡å·, å¸ƒæ—å¸¦ä½ç½®, å‡€å€¼/MA50, MA50/MA250è¶‹åŠ¿å¥åº·åº¦, å‡€å€¼/MA250, è¯•æ°´ä¹°ä»·
        return (
            f"| `{row['åŸºé‡‘ä»£ç ']}` | {row['MACDä¿¡å·']} | {row['å¸ƒæ—å¸¦ä½ç½®']} | "
            f"{format_technical_value(row['å‡€å€¼/MA50'], 'decimal2')} | {trend_status} | "
            f"{format_technical_value(row['å‡€å€¼/MA250'], 'decimal2') if not pd.isna(row['å‡€å€¼/MA250']) else '---'} | `{trial_price:.4f}` |\n"
        )

# --- æŠ¥å‘Šç”Ÿæˆ (å‡½æ•°é…ç½® 12/13) ---
def generate_report(results, timestamp_str):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Šï¼Œä½¿ç”¨ç»¼åˆè¯„åˆ†å®ç° V5.0 æœ€ç»ˆå†³ç­–æ’åºï¼Œå¹¶å¢åŠ ä¿¡å·ä¸‹é™è¿‡æ»¤ã€‚
    """
    try:
        if not results:
            return (f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                    f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°ä»»ä½•æœ‰æ•ˆçš„åŸºé‡‘æ•°æ®ã€‚**")

        df_results = pd.DataFrame(results)
        
        # 1. è¿‡æ»¤ï¼šåªä¿ç•™å›æ’¤è¾¾åˆ° MIN_MONTH_DRAWDOWN çš„åŸºé‡‘
        df_filtered = df_results[df_results['æœ€å¤§å›æ’¤'] >= MIN_MONTH_DRAWDOWN].copy()
        
        if df_filtered.empty:
            return (f"# åŸºé‡‘ V5.0 ç­–ç•¥é€‰è‚¡æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                    f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰çš„åŸºé‡‘ã€‚**")


        # 2. V5.0 ä¿¡å·åˆ†æ•° (Signal Score)
        df_filtered['signal_score'] = 0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ’¥ã€ç½‘æ ¼çº§ã€‘'), 'signal_score'] = 5
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸŒŸã€ç½‘æ ¼çº§ã€‘'), 'signal_score'] = 4.5
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘'), 'signal_score'] = 4
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘'), 'signal_score'] = 3
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘'), 'signal_score'] = 2
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ã€éœ‡è¡-å…³æ³¨ã€‘'), 'signal_score'] = 1
        
        # 3. è¶‹åŠ¿è¿‡æ»¤å™¨ (Trend Filter)
        def get_trend_score(row):
            trend = row['MA50/MA250è¶‹åŠ¿']
            ratio = row['MA50/MA250']
            
            if pd.isna(ratio) or trend == 'æ•°æ®ä¸è¶³':
                return 50 # æ•°æ®ä¸è¶³/éœ€äººå·¥å®¡æ ¸
                
            if trend == 'å‘ä¸‹' or ratio < TREND_HEALTH_THRESHOLD:
                return 0 # æ‹’ç»ä¹°å…¥
            
            return 100 # å…è®¸ä¹°å…¥

        df_filtered['trend_score'] = df_filtered.apply(get_trend_score, axis=1)

        # 4. V5.0 ç»¼åˆè¯„åˆ† (Final Score)
        df_filtered['final_score'] = df_filtered['signal_score'] * (df_filtered['trend_score'] / 100) * 1000 + (df_filtered['æœ€å¤§å›æ’¤'] * 100)
        
        # 5. åˆ†ç»„
        # A. å¯è¯•ä»“/æœ€ä½³å…±æŒ¯ï¼šè¶‹åŠ¿å¥åº· AND ä¿¡å·åˆ†æ•° >= MIN_BUY_SIGNAL_SCORE (4.0)
        df_buy = df_filtered[(df_filtered['trend_score'] == 100) & (df_filtered['signal_score'] >= MIN_BUY_SIGNAL_SCORE)].copy()
        
        # B. å¼±ä¿¡å·/ç­‰å¾…ç¡®è®¤ï¼šè¶‹åŠ¿å¥åº· AND ä¿¡å·åˆ†æ•° < MIN_BUY_SIGNAL_SCORE (å¦‚ å…³æ³¨/é¢„è­¦)
        df_weak_signal = df_filtered[(df_filtered['trend_score'] == 100) & (df_filtered['signal_score'] < MIN_BUY_SIGNAL_SCORE)].copy()
        
        # C. è¶‹åŠ¿ä¸æ˜ç¡®ï¼šè¶‹åŠ¿åˆ†æ•° = 50
        df_need_check = df_filtered[df_filtered['trend_score'] == 50].copy()
        
        # D. è¶‹åŠ¿ä¸å¥åº·ï¼šè¶‹åŠ¿åˆ†æ•° = 0
        df_reject_trend = df_filtered[df_filtered['trend_score'] == 0].copy()
        
        
        # 6. æŠ¥å‘Šæ’åº (å„è‡ªç»„å†…æ’åº)
        # å¯è¯•ä»“ç»„ï¼šæŒ‰ä¿¡å·åˆ†æ•°å’Œå›æ’¤æ’åº (æœ€é«˜ä¼˜å…ˆçº§)
        df_buy_sorted = df_buy.sort_values(by=['signal_score', 'æœ€å¤§å›æ’¤'], ascending=[False, False])
        # å¼±ä¿¡å·ç»„ï¼šæŒ‰ä¿¡å·åˆ†æ•°å’Œå›æ’¤æ’åº (ä¸­ç­‰ä¼˜å…ˆçº§)
        df_weak_signal_sorted = df_weak_signal.sort_values(by=['signal_score', 'æœ€å¤§å›æ’¤'], ascending=[False, False])
        # æ‹’ç»/å®¡æ ¸ç»„ï¼šæŒ‰å›æ’¤æ’åº (æ¬¡è¦ä¼˜å…ˆçº§)
        df_need_check_sorted = df_need_check.sort_values(by='æœ€å¤§å›æ’¤', ascending=False)
        df_reject_trend_sorted = df_reject_trend.sort_values(by='æœ€å¤§å›æ’¤', ascending=False)
        
        
        report_parts = []
        report_parts.extend([
            f"# åŸºé‡‘ V5.0 ç­–ç•¥é€‰è‚¡æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{len(df_filtered)}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€å›æ’¤æ¡ä»¶ï¼ˆ$\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰ã€‚\n",
            f"å…¶ä¸­ï¼Œ**{len(df_buy)}** åªåŸºé‡‘åŒæ—¶æ»¡è¶³ **è¶‹åŠ¿å¥åº·åº¦** å’Œ **æœ€ä½ä¿¡å·å¼ºåº¦** ($\ge {MIN_BUY_SIGNAL_SCORE:.1f}$)ï¼Œè¢«åˆ—ä¸º**æœ€ä½³è¯•ä»“ç›®æ ‡**ã€‚\n",
            f"**å†³ç­–é‡ç‚¹ï¼š** **V5.0 ç­–ç•¥å¯åŠ¨å¿…é¡»å…ˆè¿›è¡Œå®è§‚ç¯å¢ƒåˆ¤æ–­ï¼** è¯·ä¼˜å…ˆä» I ç»„é€‰æ‹©æ ‡çš„ã€‚\n",
            f"\n---\n"
        ])
        
        
        # A. ã€å¯è¯•ä»“/æœ€é«˜ä¼˜å…ˆçº§ã€‘ (é€šè¿‡è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸ & å¼ºä¿¡å·)
        if not df_buy_sorted.empty:
            report_parts.extend([
                f"\n## ğŸ† I. ã€V5.0 å¯è¯•ä»“/æœ€ä½³å…±æŒ¯ç›®æ ‡ã€‘ ({len(df_buy_sorted)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¿™äº›åŸºé‡‘ **è¶‹åŠ¿å¥åº·** ä¸”å…·æœ‰ **å¼ºä¿¡å·**ï¼ˆç½‘æ ¼çº§/é«˜å¸/é˜²å¾¡ï¼‰ï¼Œæ˜¯**ä¼˜å…ˆé€‰æ‹©**çš„è¯•ä»“æ ‡çš„ã€‚\n\n"
            ])
            report_parts.extend(generate_group_tables(df_buy_sorted))

        
        # B. ã€å¼±ä¿¡å·/ç­‰å¾…ç¡®è®¤ã€‘ (è¶‹åŠ¿å¥åº· & å¼±ä¿¡å·)
        if not df_weak_signal_sorted.empty:
            report_parts.extend([
                f"\n## ğŸ’¡ II. ã€å¼±ä¿¡å·/ç­‰å¾…ç¡®è®¤ã€‘ ({len(df_weak_signal_sorted)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¿™äº›åŸºé‡‘ **è¶‹åŠ¿å¥åº·** ä½†ä¿¡å·è¾ƒå¼±ï¼ˆå¦‚ã€å…³æ³¨ã€‘/ã€é¢„è­¦ã€‘ï¼‰ã€‚**éœ€ç­‰å¾…ä¿¡å·å¢å¼ºï¼Œæˆ–åœ¨æç‰¹æ®Šæƒ…å†µä¸‹å°‘é‡è¯•ä»“ã€‚**\n\n"
            ])
            report_parts.extend(generate_group_tables(df_weak_signal_sorted))
        
        
        # C. ã€è¶‹åŠ¿ä¸æ˜ç¡®/éœ€äººå·¥å®¡æ ¸ã€‘ (æ•°æ®ä¸è¶³)
        if not df_need_check_sorted.empty:
            report_parts.extend([
                f"\n## ğŸ” III. ã€è¶‹åŠ¿ä¸æ˜ç¡®/éœ€äººå·¥å®¡æ ¸ã€‘ ({len(df_need_check_sorted)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¿™äº›åŸºé‡‘**æ•°æ®ä¸è¶³ 250 å¤©** æˆ– **æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æœ‰è¯¯**ã€‚å›æ’¤å·²è¾¾æ ‡ï¼Œä½†éœ€**æ‰‹åŠ¨æ ¸æŸ¥** MA50/MA250 å¥åº·åº¦ã€‚\n\n"
            ])
            report_parts.extend(generate_group_tables(df_need_check_sorted))
            

        # D. ã€è¶‹åŠ¿ä¸å¥åº·/å¿…é¡»æ”¾å¼ƒã€‘ (æœªé€šè¿‡è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸)
        if not df_reject_trend_sorted.empty:
            report_parts.extend([
                f"\n## âŒ IV. ã€è¶‹åŠ¿ä¸å¥åº·/å¿…é¡»æ”¾å¼ƒã€‘ ({len(df_reject_trend_sorted)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¿™äº›åŸºé‡‘**æœªé€šè¿‡è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸**ã€‚**é£é™©è¿‡é«˜ï¼Œè¯·æ”¾å¼ƒè¯•ä»“ã€‚**\n\n"
            ])
            report_parts.extend(generate_group_tables(df_reject_trend_sorted))


        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ï¼ˆæœ€åå†æ¬¡å¼ºè°ƒ V5.0 çš„å®è§‚åˆ¤æ–­ï¼‰
        report_parts.extend([
            "\n---\n",
            f"## **âš ï¸ V5.0 å®è§‚ç¯å¢ƒä¸è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸æ€»ç»“**\n\n",
            f"**1. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼ˆMA50/MA250 å†³å®šèƒ½å¦ä¹°ï¼‰ï¼š**\n",
            f"Â  Â  * **è¶‹åŠ¿å¥åº·**ï¼šMA50/MA250 $\\ge {TREND_HEALTH_THRESHOLD}$ ä¸” è¶‹åŠ¿æ–¹å‘ä¸º 'å‘ä¸Š' æˆ– 'å¹³ç¨³'ï¼Œå…è®¸è¯•ä»“ã€‚\n",
            f"Â  Â  * **è¶‹åŠ¿ä¸å¥åº·**ï¼šè‹¥åŸºé‡‘æ˜¾ç¤º **âš ï¸ å‘ä¸‹**ï¼Œæˆ– MA50/MA250 $< {TREND_HEALTH_THRESHOLD}$ï¼Œ**å¿…é¡»æ”¾å¼ƒè¯•ä»“**ã€‚\n",
            f"**2. ğŸŒ V1.0 è¯•ä»“å§¿æ€ç¡®è®¤ï¼ˆå®è§‚ç¯å¢ƒå†³å®šä»“ä½ï¼‰ï¼š**\n",
            f"Â  Â  * **åœ¨æ‰§è¡Œè¯•ä»“å‰ï¼Œå¿…é¡»æ‰‹åŠ¨åˆ¤æ–­å®è§‚ç¯å¢ƒï¼ˆç‰›å¸‚/éœ‡è¡å¸‚/ç†Šå¸‚ï¼‰ï¼Œå¹¶æ ¹æ® V5.0 æ‰‹å†Œç¡®å®šä»“ä½ï¼ˆ5%, 10%, 20%ï¼‰å’Œæ´»æ€§åŒºé—´**ã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

# --- è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆè¡¨æ ¼ (å‡½æ•°é…ç½® 13/13) ---
def generate_group_tables(df_group):
    
    TABLE_1_HEADER = f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥æ¶¨è·Œå¹…** | RSI(14) | **RSI(6)** | V5.0 ä¿¡å· |\n"
    TABLE_1_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
    TABLE_2_HEADER = f"| åŸºé‡‘ä»£ç  | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250å¥åº·åº¦** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) |\n"
    TABLE_2_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
    
    parts = []
    
    parts.extend([
        "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
        TABLE_1_HEADER,
        TABLE_1_SEPARATOR
    ])

    current_index = 0
    for _, row in df_group.iterrows():
        current_index += 1
        parts.append(format_table_row(current_index, row, table_part=1))
        
    parts.extend([
        "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
        TABLE_2_HEADER,
        TABLE_2_SEPARATOR
    ])

    current_index = 0 
    for _, row in df_group.iterrows():
        current_index += 1
        parts.append(format_table_row(current_index, row, table_part=2))
        
    parts.append("\n---\n")
    return parts

# --- ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except Exception:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
            
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        if not os.path.isdir(FUND_DATA_DIR):
            logging.error(f"åŸºé‡‘æ•°æ®ç›®å½• '{FUND_DATA_DIR}' ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºè¯¥ç›®å½•å¹¶æ”¾å…¥ CSV æ–‡ä»¶ã€‚")
            return False

        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    success = main()
    if success:
        print(f"è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚V5.0 ç­–ç•¥æŠ¥å‘Šå·²æ›´æ–°ä¸º'æœ€ç»ˆå†³ç­–æ¨¡å¼'ï¼Œå¹¶å·²è®¾ç½®å¯è¯•ä»“ä¿¡å·ä¸‹é™ (Score >= {MIN_BUY_SIGNAL_SCORE:.1f})ã€‚")
    else:
        print("è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ fund_analysis.log æ–‡ä»¶ä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")