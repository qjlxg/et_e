import pandas as pd
import requests
from datetime import datetime
import os
import time
from io import StringIO
from typing import Optional, List
import logging
from pathlib import Path
import re

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FundHoldingsFetcher:
    """åŸºé‡‘æŒä»“æ•°æ®æŠ“å–å™¨"""
    
    def __init__(self, base_url: str = "http://fundf10.eastmoney.com"):
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
    
    def fetch_fund_holdings(self, fund_code: str, year: int) -> Optional[pd.DataFrame]:
        """
        ä»ä¸œæ–¹è´¢å¯Œç½‘è·å–ç‰¹å®šå¹´ä»½çš„æ‰€æœ‰åŸºé‡‘æŒä»“ä¿¡æ¯ï¼ˆåŒ…å«æ‰€æœ‰å­£åº¦ï¼‰
        
        Args:
            fund_code: åŸºé‡‘ä»£ç 
            year: å¹´ä»½
            
        Returns:
            åˆå¹¶åçš„æŒä»“æ•°æ®DataFrameæˆ–None
        """
        url = f"{self.base_url}/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=10&year={year}"
        
        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            
            # ä½¿ç”¨ StringIO åŒ…è£…å­—ç¬¦ä¸²ï¼Œé¿å…FutureWarning
            tables = pd.read_html(StringIO(response.text), encoding='utf-8')
            
            if not tables:
                logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} åœ¨ {year} å¹´æ²¡æœ‰è¡¨æ ¼æ•°æ®")
                return None

            full_year_df = pd.DataFrame()
            
            for i, table in enumerate(tables):
                # ä»è¡¨æ ¼ä¸Šæ–¹çš„æ–‡æœ¬ä¸­æå–å­£åº¦ä¿¡æ¯
                quarter_match = re.search(r'(\d{4}å¹´\då­£åº¦)', response.text.split('<table')[i])
                quarter_info = quarter_match.group(1) if quarter_match else f"Q{i+1}"
                
                # æ•°æ®æ¸…æ´—
                cleaned_df = self._clean_holdings_data(table)
                
                if not cleaned_df.empty:
                    cleaned_df['å­£åº¦'] = quarter_info
                    full_year_df = pd.concat([full_year_df, cleaned_df], ignore_index=True)
            
            if not full_year_df.empty:
                logger.info(f"âœ… æˆåŠŸè·å–åŸºé‡‘ {fund_code} åœ¨ {year} å¹´çš„å…¨éƒ¨å­£åº¦æŒä»“æ•°æ®ï¼Œæ€»è®°å½•æ•°ï¼š{len(full_year_df)}")
                return full_year_df
            else:
                logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} åœ¨ {year} å¹´æ²¡æœ‰æœ‰æ•ˆçš„æŒä»“æ•°æ®")
                return None
                
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ ç½‘ç»œè¯·æ±‚å¤±è´¥ - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ è§£æHTMLè¡¨æ ¼æˆ–å¤„ç†æ•°æ®å¤±è´¥ - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}: {e}")
            return None
    
    def _clean_holdings_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…æ´—æŒä»“æ•°æ®"""
        if df.empty:
            return df
            
        # ç§»é™¤ç©ºè¡Œ
        df = df.dropna(how='all')
        
        # æ ‡å‡†åŒ–åˆ—å
        if not df.columns.empty:
            df.columns = df.columns.str.strip()
        
        # è½¬æ¢æ•°å€¼åˆ—
        numeric_cols = ['å å‡€å€¼æ¯”ä¾‹', 'æŒè‚¡æ•°ï¼ˆä¸‡è‚¡ï¼‰', 'æŒä»“å¸‚å€¼ï¼ˆä¸‡å…ƒï¼‰']
        for col in numeric_cols:
            if col in df.columns:
                # ç§»é™¤å¯èƒ½çš„é€—å·æˆ–ç™¾åˆ†å·
                df[col] = df[col].astype(str).str.replace(',', '').str.replace('%', '')
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ä¸¢å¼ƒæ— æ•ˆè¡Œ
        df = df.dropna(subset=['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°'])
        
        return df
    
    def batch_fetch(self, fund_codes: List[str], years: List[int], 
                    input_file: str, output_dir: str = 'fund_data') -> dict:
        """
        æ‰¹é‡æŠ“å–åŸºé‡‘æŒä»“æ•°æ®
        
        Args:
            fund_codes: åŸºé‡‘ä»£ç åˆ—è¡¨
            years: è¦æŠ“å–çš„å¹´ä»½åˆ—è¡¨
            input_file: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æŠ“å–ç»“æœç»Ÿè®¡å­—å…¸
        """
        results = {'success': 0, 'failed': 0, 'total': len(fund_codes) * len(years)}
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        Path(output_dir).mkdir(exist_ok=True)
        
        # è¯»å–è¾“å…¥æ–‡ä»¶
        try:
            input_df = pd.read_csv(input_file)
            logger.info(f"ğŸ“Š è¯»å–è¾“å…¥æ–‡ä»¶ï¼š{input_file}ï¼ŒåŒ…å« {len(input_df)} æ¡è®°å½•")
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è¯»å–è¾“å…¥æ–‡ä»¶ {input_file}: {e}")
            return results
        
        # ç¡®ä¿åŸºé‡‘ä»£ç æ ¼å¼æ­£ç¡®
        fund_codes = [str(code).zfill(6) for code in fund_codes]
        
        for i, code in enumerate(fund_codes, 1):
            for year in years:
                logger.info(f"[{i}/{len(fund_codes)}] ğŸ” å¤„ç†åŸºé‡‘ {code} - {year}å¹´")
                
                holdings_df = self.fetch_fund_holdings(code, year)
                
                if holdings_df is not None and not holdings_df.empty:
                    # ä¿å­˜æ•°æ®
                    filename = f'æŒä»“_{code}_{year}.csv'
                    output_path = Path(output_dir) / filename
                    
                    holdings_df.to_csv(output_path, index=False, encoding='utf-8-sig')
                    logger.info(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {output_path}")
                    results['success'] += 1
                else:
                    results['failed'] += 1
                
                # å»¶æ—¶é¿å…è¢«å°
                time.sleep(2)
        
        logger.info(f"ğŸ‰ æ‰¹é‡æŠ“å–å®Œæˆï¼æˆåŠŸ: {results['success']}, å¤±è´¥: {results['failed']}")
        return results

    def analyze_holdings_changes(self, fund_code: str, years: List[int], output_dir: str = 'fund_data', 
                                 analysis_dir: str = 'fund_analysis') -> dict:
        """
        åˆ†æåŸºé‡‘æŒä»“å˜åŒ–
        
        Args:
            fund_code: åŸºé‡‘ä»£ç 
            years: å¹´ä»½åˆ—è¡¨
            output_dir: æŒä»“æ•°æ®ç›®å½•
            analysis_dir: åˆ†æè¾“å‡ºç›®å½•
            
        Returns:
            åˆ†æç»“æœç»Ÿè®¡
        """
        Path(analysis_dir).mkdir(exist_ok=True)
        results = {'analyzed_pairs': 0, 'total_pairs': len(years) - 1}
        
        data_dict = {}
        for year in years:
            file_path = Path(output_dir) / f'æŒä»“_{fund_code}_{year}.csv'
            if file_path.exists():
                df = pd.read_csv(file_path, encoding='utf-8-sig')
                data_dict[year] = df # è¯»å–æ–‡ä»¶åç›´æ¥ä½¿ç”¨
            else:
                logger.warning(f"âš ï¸ ç¼ºå°‘ {fund_code} {year}å¹´çš„æŒä»“æ•°æ®æ–‡ä»¶")
        
        if len(data_dict) < 2:
            logger.warning(f"âš ï¸ åŸºé‡‘ {fund_code} å¯ç”¨å¹´ä»½ä¸è¶³ï¼Œæ— æ³•åˆ†æå˜åŒ–")
            return results
        
        sorted_years = sorted(data_dict.keys())
        for i in range(len(sorted_years) - 1):
            year1 = sorted_years[i]
            year2 = sorted_years[i+1]
            
            df1 = data_dict[year1]
            df2 = data_dict[year2]
            
            # åˆå¹¶æ•°æ®
            merged = pd.merge(
                df1[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'å å‡€å€¼æ¯”ä¾‹']],
                df2[['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'å å‡€å€¼æ¯”ä¾‹']],
                on=['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°'],
                how='outer',
                suffixes=(f'_{year1}', f'_{year2}')
            )
            
            # è®¡ç®—å˜åŒ–
            prop_col1 = f'å å‡€å€¼æ¯”ä¾‹_{year1}'
            prop_col2 = f'å å‡€å€¼æ¯”ä¾‹_{year2}'
            
            merged[prop_col1] = merged[prop_col1].fillna(0)
            merged[prop_col2] = merged[prop_col2].fillna(0)
            
            merged['æ¯”ä¾‹å˜åŒ–'] = merged[prop_col2] - merged[prop_col1]
            merged['å˜åŒ–ç±»å‹'] = merged.apply(
                lambda row: 'æ–°ä¹°å…¥' if row[prop_col1] == 0 else 
                            'å–å‡º' if row[prop_col2] == 0 else 
                            'å¢åŠ ' if row['æ¯”ä¾‹å˜åŒ–'] > 0 else 
                            'å‡å°‘' if row['æ¯”ä¾‹å˜åŒ–'] < 0 else 'ä¸å˜',
                axis=1
            )
            
            # æ’åºæŒ‰å˜åŒ–ç»å¯¹å€¼
            merged = merged.sort_values(by='æ¯”ä¾‹å˜åŒ–', key=abs, ascending=False)
            
            # ä¿å­˜åˆ†æç»“æœ
            filename = f'å˜åŒ–_{fund_code}_{year1}_{year2}.csv'
            output_path = Path(analysis_dir) / filename
            merged.to_csv(output_path, index=False, encoding='utf-8-sig')
            logger.info(f"ğŸ“ˆ æŒä»“å˜åŒ–åˆ†æå·²ä¿å­˜: {output_path}")
            
            results['analyzed_pairs'] += 1
        
        return results

    def batch_analyze(self, fund_codes: List[str], years: List[int], 
                      output_dir: str = 'fund_data', analysis_dir: str = 'fund_analysis') -> dict:
        """
        æ‰¹é‡åˆ†ææŒä»“å˜åŒ–
        
        Args:
            fund_codes: åŸºé‡‘ä»£ç åˆ—è¡¨
            years: å¹´ä»½åˆ—è¡¨
            output_dir: æŒä»“æ•°æ®ç›®å½•
            analysis_dir: åˆ†æè¾“å‡ºç›®å½•
            
        Returns:
            æ‰¹é‡åˆ†æç»Ÿè®¡
        """
        batch_results = {'success': 0, 'failed': 0, 'total': len(fund_codes)}
        
        for i, code in enumerate(fund_codes, 1):
            logger.info(f"[{i}/{len(fund_codes)}] ğŸ“Š åˆ†æåŸºé‡‘ {code} æŒä»“å˜åŒ–")
            results = self.analyze_holdings_changes(code, years, output_dir, analysis_dir)
            if results['analyzed_pairs'] > 0:
                batch_results['success'] += 1
            else:
                batch_results['failed'] += 1
        
        logger.info(f"ğŸ‰ æ‰¹é‡åˆ†æå®Œæˆï¼æˆåŠŸ: {batch_results['success']}, å¤±è´¥: {batch_results['failed']}")
        return batch_results

def main():
    """ä¸»å‡½æ•°"""
    # å½“å‰æ—¥æœŸ
    today_date = datetime.now().strftime('%Y%m%d')
    input_csv_path = f'data/ä¹°å…¥ä¿¡å·åŸºé‡‘_{today_date}.csv'
    
    logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡ŒåŸºé‡‘æŒä»“æ•°æ®æŠ“å–ä»»åŠ¡")
    logger.info(f"ğŸ“… å½“å‰æ—¥æœŸ: {today_date}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not Path(input_csv_path).exists():
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv_path}")
        logger.info("ğŸ’¡ è¯·ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼Œæˆ–è€…æ‰‹åŠ¨åˆ›å»ºç¤ºä¾‹æ–‡ä»¶")
        return
    
    # è¯»å–åŸºé‡‘ä»£ç 
    try:
        df = pd.read_csv(input_csv_path)
        fund_codes = df['fund_code'].unique().tolist()
        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(fund_codes)} ä¸ªå”¯ä¸€åŸºé‡‘ä»£ç ")
    except Exception as e:
        logger.error(f"âŒ è¯»å–åŸºé‡‘ä»£ç å¤±è´¥: {e}")
        return
    
    # é…ç½®æŠ“å–å‚æ•°
    years_to_fetch = [2023, 2024, 2025]
    output_dir = 'fund_data'
    analysis_dir = 'fund_analysis'
    
    # åˆ›å»ºæŠ“å–å™¨å®ä¾‹
    fetcher = FundHoldingsFetcher()
    
    # æ‰§è¡Œæ‰¹é‡æŠ“å–
    fetch_results = fetcher.batch_fetch(
        fund_codes=fund_codes,
        years=years_to_fetch,
        input_file=input_csv_path,
        output_dir=output_dir
    )
    
    # æ‰§è¡Œæ‰¹é‡åˆ†æ
    analyze_results = fetcher.batch_analyze(
        fund_codes=fund_codes,
        years=years_to_fetch,
        output_dir=output_dir,
        analysis_dir=analysis_dir
    )
    
    # è¾“å‡ºæ€»ç»“
    logger.info("=" * 50)
    logger.info("ğŸ“Š ä»»åŠ¡æ€»ç»“")
    logger.info(f"æŠ“å–æ€»ä»»åŠ¡æ•°: {fetch_results['total']}")
    logger.info(f"æŠ“å–æˆåŠŸ: {fetch_results['success']}")
    logger.info(f"æŠ“å–å¤±è´¥: {fetch_results['failed']}")
    logger.info(f"åˆ†ææˆåŠŸåŸºé‡‘: {analyze_results['success']}")
    logger.info(f"åˆ†æå¤±è´¥åŸºé‡‘: {analyze_results['failed']}")
    logger.info("=" * 50)

if __name__ == "__main__":
    main()
