import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- é…ç½®å‚æ•° (å®Œæ•´ä¿ç•™) ---
FUND_DATA_DIR = 'fund_data'
MIN_CONSECUTIVE_DROP_DAYS = 3
MIN_MONTH_DRAWDOWN = 0.06
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.10  # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (10%)
MIN_DAILY_DROP_PERCENT = 0.03  # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ (å®Œæ•´ä¿ç•™) ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 
STRONG_RSI_THRESHOLD_P2 = 35.0

# --- è®¾ç½®æ—¥å¿— (å‡½æ•°é…ç½® 1/13) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- éªŒè¯æ•°æ® (å‡½æ•°é…ç½® 2/13) ---
def validate_fund_data(df, fund_code):
    """éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    if df.empty: 
        return False, "æ•°æ®ä¸ºç©º"
    # æ³¨æ„ï¼šæ ¹æ®æ‚¨çš„CSVæ–‡ä»¶ï¼Œå‡€å€¼åˆ—åä¸º 'net_value'
    if 'net_value' not in df.columns: 
        return False, "ç¼ºå°‘å‡€å€¼åˆ— 'net_value'"
    if len(df) < 250: 
        return False, f"æ•°æ®ç‚¹ä¸è¶³ (å½“å‰: {len(df)})"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼ (åªæ£€æŸ¥å…³é”®åˆ—)
    if df['net_value'].isnull().any():
         return False, "å…³é”®åˆ— 'net_value' å­˜åœ¨ç¼ºå¤±å€¼"
         
    return True, "æ•°æ®æœ‰æ•ˆ"

# --- æ•°æ®åŠ è½½å’Œé¢„å¤„ç† (å‡½æ•°é…ç½® 3/13) ---
def load_and_prepare_data(file_path):
    """åŠ è½½æ•°æ®ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®ï¼Œå¹¶è®¡ç®—å›æŠ¥ç‡"""
    try:
        df = pd.read_csv(file_path)
        # ç»Ÿä¸€åˆ—å
        df.columns = [col.lower() for col in df.columns]
        
        # ç¡®ä¿æ—¥æœŸæ˜¯å‡åºæ’åˆ—ï¼Œè¿™æ˜¯è®¡ç®—æ—¶é—´åºåˆ—æŒ‡æ ‡çš„åŸºç¡€
        df.sort_values(by='date', inplace=True)
        
        # è®¡ç®—æ¯æ—¥å›æŠ¥ç‡ï¼ˆç™¾åˆ†æ¯”å½¢å¼ï¼Œä¾‹å¦‚ 0.0379 -> 3.79ï¼‰
        df['daily_return'] = df['net_value'].pct_change() * 100
        
        # ç§»é™¤ä»»ä½•å¯èƒ½å›  pct_change äº§ç”Ÿçš„ NaNï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€è¡Œï¼‰
        df.dropna(subset=['net_value', 'daily_return'], inplace=True)
        
        return df
    except Exception as e:
        logging.error(f"åŠ è½½æˆ–é¢„å¤„ç†æ•°æ® {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return pd.DataFrame()

# --- RSI è®¡ç®— (å‡½æ•°é…ç½® 4/13) ---
def calculate_rsi(df, period=14):
    """è®¡ç®— RSI (ç›¸å¯¹å¼ºå¼±æŒ‡æ•°)"""
    df['up'] = df['daily_return'].apply(lambda x: x if x > 0 else 0)
    df['down'] = df['daily_return'].apply(lambda x: -x if x < 0 else 0)

    # ä½¿ç”¨ ewm (æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡)
    df['avg_up'] = df['up'].ewm(span=period, adjust=False).mean()
    df['avg_down'] = df['down'].ewm(span=period, adjust=False).mean()

    # è®¡ç®— RS (ç›¸å¯¹å¼ºåº¦)
    # é¿å…é™¤ä»¥é›¶ï¼Œå¦‚æœ avg_down ä¸ºé›¶ï¼Œåˆ™ rs è®¾ä¸ºæ— ç©·å¤§
    df['rs'] = df['avg_up'] / df['avg_down'].replace(0, np.inf)

    # è®¡ç®— RSI
    df['rsi'] = 100 - (100 / (1 + df['rs']))
    
    # è¿”å›æœ€æ–°çš„ RSI å€¼
    return df['rsi'].iloc[-1]

# --- æœ€å¤§å›æ’¤è®¡ç®— (å‡½æ•°é…ç½® 5/13) ---
def calculate_max_drawdown(df, period_days):
    """è®¡ç®—æŒ‡å®šå‘¨æœŸå†…çš„æœ€å¤§å›æ’¤"""
    
    if len(df) < period_days:
        return 0.0
    
    # é€‰å–æœ€è¿‘ period_days çš„æ•°æ®
    period_df = df.iloc[-period_days:].copy() # ä½¿ç”¨ copy é¿å… SettingWithCopyWarning
    
    # 1. è®¡ç®—ç´¯è®¡æœ€é«˜å‡€å€¼
    period_df['cumulative_max'] = period_df['net_value'].cummax()
    
    # 2. è®¡ç®—å›æ’¤ (Drawdown)
    period_df['drawdown'] = (period_df['cumulative_max'] - period_df['net_value']) / period_df['cumulative_max']
    
    # 3. æ‰¾åˆ°æœ€å¤§å›æ’¤
    max_drawdown = period_df['drawdown'].max()
    
    return max_drawdown

# --- è¿è·Œå¤©æ•°è®¡ç®— (å‡½æ•°é…ç½® 6/13) ---
def calculate_consecutive_drop_days(df):
    """è®¡ç®—æœ€æ–°çš„è¿ç»­ä¸‹è·Œå¤©æ•°"""
    df['is_drop'] = df['daily_return'] < 0
    
    # åè½¬ is_drop åˆ—ï¼Œç„¶åè®¡ç®—è¿ç»­ True çš„å¤©æ•°
    consecutive_drop = 0
    for is_drop in reversed(df['is_drop'].iloc[:-1]): # ä¸è®¡ç®—æœ€æ–°ä¸€å¤©ï¼Œå› ä¸ºæœ€æ–°ä¸€å¤©å¯èƒ½ä¸Šæ¶¨ï¼ˆå·²åœ¨æ¯æ—¥å›æŠ¥ç‡ä¸­ä½“ç°ï¼‰
        if is_drop:
            consecutive_drop += 1
        else:
            break
            
    return consecutive_drop

# --- ç­–ç•¥åˆ¤æ–­ (å‡½æ•°é…ç½® 7/13) ---
def determine_strategy_tip(rsi, max_drawdown_1m, max_drawdown_1y, latest_daily_return):
    """æ ¹æ®æŒ‡æ ‡ç¡®å®šè¡ŒåŠ¨æç¤º (Strategy Tip)"""
    action_tip = ""

    # P1: æå€¼è¶…å– (RSI æä½)
    if rsi <= EXTREME_RSI_THRESHOLD_P1:
        action_tip += f"ğŸŒŸ P1-æå€¼è¶…å– (RSI<={EXTREME_RSI_THRESHOLD_P1})"

    # P2: å¼ºåŠ›è¶…å– (RSI ä½)
    elif rsi <= STRONG_RSI_THRESHOLD_P2:
        action_tip += f"ğŸ’« P2-å¼ºåŠ›è¶…å– (RSI<={STRONG_RSI_THRESHOLD_P2})"

    # å…¶å®ƒç­–ç•¥æ¡ä»¶... (ä¾‹å¦‚é«˜å¼¹æ€§ã€è¿è·Œç­‰ï¼Œæ­¤å¤„ä»…å±•ç¤ºä¸RSIç›¸å…³çš„)

    # è¡¥å……ä¿¡æ¯ï¼šæœ€å¤§å›æ’¤è¿‡å¤§
    if max_drawdown_1m > HIGH_ELASTICITY_MIN_DRAWDOWN:
        if action_tip:
             action_tip += " | "
        action_tip += "âš ï¸ 1Må›æ’¤è¿‡å¤§"
        
    # å¦‚æœæ²¡æœ‰ä»»ä½•æç¤ºï¼Œæä¾›é»˜è®¤ä¿¡æ¯
    if not action_tip:
        action_tip = "ğŸ‘€ æŒç»­è§‚å¯Ÿ"

    return action_tip

# --- å•åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 8/13) ---
def analyze_single_fund(file_path):
    """åˆ†æå•ä¸ªåŸºé‡‘æ•°æ®å¹¶è¿”å›ç»“æœå­—å…¸"""
    fund_code = os.path.basename(file_path).split('.')[0]
    df = load_and_prepare_data(file_path)
    
    is_valid, reason = validate_fund_data(df, fund_code)
    if not is_valid:
        logging.warning(f"åŸºé‡‘ {fund_code} æ•°æ®æ— æ•ˆ: {reason}")
        return None

    try:
        # 1. è®¡ç®— RSI
        rsi = calculate_rsi(df, period=14)
        
        # 2. è®¡ç®—æœ€å¤§å›æ’¤
        max_drawdown_1m = calculate_max_drawdown(df, period_days=20) # å‡è®¾ 1M çº¦ä¸º 20 ä¸ªäº¤æ˜“æ—¥
        max_drawdown_1y = calculate_max_drawdown(df, period_days=250) # å‡è®¾ 1Y çº¦ä¸º 250 ä¸ªäº¤æ˜“æ—¥
        
        # 3. è·å–æœ€æ–°å›æŠ¥ç‡ (ç™¾åˆ†æ¯”)
        latest_daily_return = df['daily_return'].iloc[-1]
        
        # 4. è·å–å½“æ—¥å‡€å€¼ (ç”¨äºåç»­åˆ¤æ–­å’ŒæŠ¥å‘Š)
        latest_net_value = df['net_value'].iloc[-1]
        
        # 5. ç¡®å®šè¡ŒåŠ¨æç¤º
        action_tip = determine_strategy_tip(rsi, max_drawdown_1m, max_drawdown_1y, latest_daily_return)

        result = {
            'fund_code': fund_code,
            'rsi': rsi,
            'max_drawdown_1m': max_drawdown_1m,
            'max_drawdown_1y': max_drawdown_1y,
            'latest_daily_return': latest_daily_return,
            'latest_net_value': latest_net_value,
            'action_tip': action_tip
        }
        return result

    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {fund_code} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None

# --- æ‰€æœ‰åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 9/13) ---
def analyze_all_funds():
    """éå†æ‰€æœ‰åŸºé‡‘æ•°æ®æ–‡ä»¶è¿›è¡Œåˆ†æ"""
    # glob.glob ç”¨äºæŸ¥æ‰¾å½“å‰ç›®å½•ä¸‹çš„æ‰€æœ‰ .csv æ–‡ä»¶ï¼Œæ¨¡æ‹Ÿ FUND_DATA_DIR çš„è¡Œä¸º
    file_list = glob.glob('*.csv') # å‡è®¾ .csv æ–‡ä»¶å°±åœ¨å½“å‰ç›®å½•
    
    results = []
    for file_path in file_list:
        result = analyze_single_fund(file_path)
        if result:
            results.append(result)
            
    return results

# --- æ’åºé”® (å‡½æ•°é…ç½® 10/13) ---
def sort_key_for_report(result):
    """æŠ¥å‘Šæ’åºé€»è¾‘: ä¸»è¦æŒ‰ RSI å‡åº (RSIè¶Šä½è¶Šé å‰)"""
    return result['rsi']

# --- æŠ¥å‘Šç”Ÿæˆ (å‡½æ•°é…ç½® 11/13) ---
def generate_report(results, timestamp):
    """ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ¥å‘Š"""
    try:
        report_parts = [
            f"# åŸºé‡‘è¶…å–å’Œé«˜å›æ’¤è­¦ç¤ºæŠ¥å‘Š\n",
            f"\n> **æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š** {timestamp}\n",
            f"\n## ğŸ”´ P1/P2 ç­–ç•¥è§¦å‘åŸºé‡‘åˆ—è¡¨\n",
            f"\n| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | å½“æ—¥è·Œå¹… | RSI(14) | è¡ŒåŠ¨æç¤º |\n",
            f"|:---:|:---:|:---:|:---:|:---:|:---|\n"
        ]

        # æŒ‰ç…§æ’åºé”®è¿›è¡Œæ’åº
        sorted_results = sorted(results, key=sort_key_for_report, reverse=False)

        report_table_rows = []
        
        for rank, result in enumerate(sorted_results, 1):
            
            action_tip = result.get('action_tip', 'N/A')
            
            # 1. æå–åŸå§‹å›æŠ¥ç‡ (ä¾‹å¦‚: 3.79)
            latest_daily_return = result.get('latest_daily_return', 0.0) 
            
            # 2. *** æ ¸å¿ƒä¿®æ­£é€»è¾‘ï¼šä»…åœ¨ä¸‹è·Œæ—¶æ˜¾ç¤ºè´Ÿç™¾åˆ†æ¯” ***
            if latest_daily_return < 0:
                # å®é™…ä¸‹è·Œæ—¶ï¼Œæ˜¾ç¤ºè´Ÿç™¾åˆ†æ¯”
                display_percent = latest_daily_return
            else:
                # å®é™…ä¸Šæ¶¨æˆ–æŒå¹³æ—¶ï¼Œæ˜¾ç¤º 0.00%
                display_percent = 0.00 
            # **********************************************

            # æ ¼å¼åŒ–è¾“å‡ºåˆ°è¡¨æ ¼
            report_table_rows.append(
                f"|{rank}|{result['fund_code']}|{result['max_drawdown_1m']:.2%}|{display_percent:.2%}|{result['rsi']:.2f}|{action_tip}|"
            )
            
        report_parts.extend(report_table_rows)

        # æŠ¥å‘Šæ€»ç»“å’Œæ“ä½œå»ºè®® (ä¿æŒä¸å˜)
        report_parts.extend([
            f"\n## ğŸ› ï¸ ç­–ç•¥è¯´æ˜ä¸æ“ä½œå»ºè®®\n",
            f"\n**1. æŒ‡æ ‡å®šä¹‰ï¼š**\n",
            f"    * **RSI(14)ï¼š** åŸºäº 14 å¤©æ”¶ç›˜ä»·çš„ç›¸å¯¹å¼ºå¼±æŒ‡æ•°ï¼Œä½äº {EXTREME_RSI_THRESHOLD_P1} ä¸ºæå€¼è¶…å– (P1)ã€‚\n",
            f"    * **æœ€å¤§å›æ’¤ (1M)ï¼š** æœ€è¿‘ 20 ä¸ªäº¤æ˜“æ—¥å†…ï¼ŒåŸºé‡‘å‡€å€¼ä»æœ€é«˜ç‚¹ä¸‹è·Œçš„ç™¾åˆ†æ¯”æœ€å¤§å€¼ã€‚\n",
            f"\n**2. è¡ŒåŠ¨æç¤ºç­‰çº§ï¼š**\n",
            f"    * ğŸŒŸ P1-æå€¼è¶…å–ï¼šå¸‚åœºæƒ…ç»ªæåº¦ææ…Œï¼Œè¾¾åˆ°å¼ºçƒˆè§‚å¯Ÿæˆ–åº•ä»“å»ºä»“æ¡ä»¶ã€‚\n",
            f"    * ğŸ’« P2-å¼ºåŠ›è¶…å–ï¼šå¤„äºåº•éƒ¨åŒºåŸŸï¼Œå¯è¿›è¡Œå°‘é‡å…³æ³¨å’Œåˆ†æ‰¹è¯•æ¢ã€‚\n",
            f"\n**3. æŠ•èµ„å»ºè®®ï¼š** å»ºè®®åªåœ¨ **P1/P2 æç¤º** å‡ºç°æ—¶ï¼Œæ ¹æ®ä¸ªäººé£é™©åå¥½ï¼Œè€ƒè™‘**å°ä»“ä½**æˆ–**I çº§è¯•æ°´**ã€‚\n",
            f"    * **æ³¨æ„ï¼š** æœ¬æŠ¥å‘Šä»…ä¸ºæŠ€æœ¯åˆ†æå‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚è¯·ç»“åˆåŸºæœ¬é¢å’Œå¸‚åœºç¯å¢ƒç»¼åˆåˆ¤æ–­ã€‚\n",
            f"\n**4. é£é™©æ§åˆ¶ï¼š**\n",
            f"    * ä¸¥æ ¼æ­¢æŸçº¿ï¼šå¹³å‡æˆæœ¬ä»·**è·Œå¹…è¾¾åˆ° 8%-10%**ï¼Œç«‹å³æ¸…ä»“æ­¢æŸã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

# --- ä¸»å‡½æ•° (å‡½æ•°é…ç½® 12/13) ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            # ä½¿ç”¨å¸¦æ—¶åŒºçš„å½“å‰æ—¶é—´
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
        
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
            
        logging.info(f"åˆ†æå®Œæˆã€‚æŠ¥å‘Šå·²ä¿å­˜è‡³ {report_file}")

    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºè¿è¡Œå¤±è´¥: {e}")

if __name__ == '__main__':
    main()
