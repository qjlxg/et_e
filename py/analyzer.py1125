import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- é…ç½®å‚æ•° (å®Œæ•´ä¿ç•™) ---# åªæœ‰è¿‘ä¸€ä¸ªæœˆæœ€å¤§å›æ’¤è¾¾åˆ° $15\%$ æˆ–æ›´é«˜çš„åŸºé‡‘ï¼Œæ‰ä¼šè¿›å…¥æŠ¥å‘Šä¸­çš„é«˜ä¼˜å…ˆçº§è¶…å–åˆ¤æ–­ã€‚
FUND_DATA_DIR = 'fund_data'
MIN_CONSECUTIVE_DROP_DAYS = 3#è¡¨ç¤ºæœ€å°è¿ç»­ä¸‹è·Œå¤©æ•°ä¸º 3 å¤©
MIN_MONTH_DRAWDOWN = 0.10  #(å³ 10%) æ˜¯åŸºç¡€å›æ’¤æ¡ä»¶ï¼Œæ‰€æœ‰åŸºé‡‘åªæœ‰è¾¾åˆ°è¿™ä¸ªå›æ’¤æ‰ä¼šè¢«çº³å…¥æŠ¥å‘Šã€‚
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15  # (å³ 15%) æ˜¯ç”¨äºå®šä¹‰ "é«˜å¼¹æ€§" åŸºé‡‘çš„æ›´ä¸¥æ ¼å›æ’¤æ¡ä»¶ï¼Œåªæœ‰è¾¾åˆ°è¿™ä¸ªæ¡ä»¶çš„åŸºé‡‘æ‰ä¼šè¿›å…¥æŠ¥å‘Šä¸­çš„ç¬¬ä¸€å’Œç¬¬äºŒä¼˜å…ˆçº§ (P1, P2) ç­›é€‰ï¼Œå¹¶è§¦å‘è¡ŒåŠ¨æç¤ºä¸­çš„è¶…å–åˆ¤æ–­ã€‚
MIN_DAILY_DROP_PERCENT = 0.03  # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ (å®Œæ•´ä¿ç•™) --
EXTREME_RSI_THRESHOLD_P1 = 29.0 
STRONG_RSI_THRESHOLD_P2 = 35.0

# --- è®¾ç½®æ—¥å¿— (å‡½æ•°é…ç½® 1/13) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- éªŒè¯æ•°æ® (å‡½æ•°é…ç½® 2/13) ---
def validate_fund_data(df, fund_code):
    """éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    if df.empty: return False, "æ•°æ®ä¸ºç©º"
    if 'value' not in df.columns: return False, "ç¼ºå°‘å‡€å€¼åˆ—"
    # ã€å·²ä¿ç•™ã€‘æœ€å°æ•°æ®è¦æ±‚ä¸º 60
    if len(df) < 60: return False, f"æ•°æ®ä¸è¶³60æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
    if (df['value'] <= 0).any(): return False, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
    return True, "æ•°æ®æœ‰æ•ˆ"

# --- å¸ƒæ—å¸¦è®¡ç®— (å‡½æ•°é…ç½® 3/13) ---
def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    # ç¡®ä¿æ²¡æœ‰é™¤ä»¥é›¶
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        # å½’ä¸€åŒ–ä½ç½®
        range_band = latest_upper - latest_lower
        if range_band == 0:
             return "è½¨é“ä¸­é—´" 
             
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (å‡½æ•°é…ç½® 4/13) ---
def calculate_technical_indicators(df):
    """
    è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ (RSI(14), RSI(6), MACD, MA, è¶‹åŠ¿ç­‰)
    å‡è®¾ df æ˜¯æŒ‰æ—¶é—´å‡åºæ’åˆ—çš„ï¼ˆæœ€æ–°å€¼åœ¨æœ«å°¾ï¼‰ã€‚
    """
    df_asc = df.copy()

    try:
        # è¿™é‡Œçš„åˆ¤æ–­ä¹Ÿä» 250 é™ä½åˆ° 60ï¼Œä»¥å…¼å®¹ MA50 å’Œ RSI
        if 'value' not in df_asc.columns or len(df_asc) < 60:
            return {
                'RSI(14)': np.nan, 
                'RSI(6)': np.nan, # æ–°å¢RSI(6)
                'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 
                'å‡€å€¼/MA50': np.nan,
                'å‡€å€¼/MA250': np.nan, 
                'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³',
                'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 
                'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
            }

        delta = df_asc['value'].diff()

        # 1. RSI (14) - åŸæœ‰é€»è¾‘
        gain_14 = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
        loss_14 = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs_14 = gain_14 / loss_14.replace(0, np.nan) 
        df_asc['RSI_14'] = 100 - (100 / (1 + rs_14))
        rsi_14_latest = df_asc['RSI_14'].iloc[-1]
        
        # 1.b RSI (6) - æ–°å¢é€»è¾‘
        gain_6 = (delta.where(delta > 0, 0)).rolling(window=6, min_periods=1).mean()
        loss_6 = (-delta.where(delta < 0, 0)).rolling(window=6, min_periods=1).mean()
        rs_6 = gain_6 / loss_6.replace(0, np.nan) 
        df_asc['RSI_6'] = 100 - (100 / (1 + rs_6))
        rsi_6_latest = df_asc['RSI_6'].iloc[-1]
        
        # 2. MACD (ç®€åŒ–ä¸ºä¿¡å·åˆ¤æ–­)
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            if macd_latest > signal_latest and macd_prev < signal_prev: macd_signal = 'é‡‘å‰'
            elif macd_latest < signal_latest and macd_prev > signal_prev: macd_signal = 'æ­»å‰'

        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        # MA250 è®¡ç®—ä»ç„¶ä¿ç•™ï¼Œæ•°æ®ä¸è¶³æ—¶ä¼šè‡ªåŠ¨äº§ç”Ÿ NaN
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean() 
        
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]
        
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan
        
        # åªæœ‰åœ¨æ•°æ®è¶³å¤Ÿæ—¶æ‰è®¡ç®— MA250 ç›¸å…³æŒ‡æ ‡
        if len(df_asc) < 250:
            net_to_ma250 = np.nan
            ma50_to_ma250 = np.nan
            trend_direction = 'æ•°æ®ä¸è¶³'
        else:
            net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
        
            # 4. MA50/MA250 è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
            trend_direction = 'æ•°æ®ä¸è¶³'
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(20).dropna()
            if len(recent_ratio) >= 5:
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                if slope > 0.001: trend_direction = 'å‘ä¸Š'
                elif slope < -0.001: trend_direction = 'å‘ä¸‹'
                else: trend_direction = 'å¹³ç¨³'
        
        # 5. å½“æ—¥æ¶¨è·Œå¹… (æœ€æ–°ä¸€å¤©æ¶¨è·Œå¹…)
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                # æ ‡å‡†æ¶¨è·Œå¹…ï¼š(ç°å€¼ - å‰å€¼) / å‰å€¼ã€‚è´Ÿå€¼ä»£è¡¨è·Œå¹…ï¼Œæ­£å€¼ä»£è¡¨æ¶¨å¹…ã€‚
                daily_drop = (value_latest - value_t_minus_1) / value_t_minus_1
                
        # 6. å¸ƒæ—å¸¦ä½ç½® (è°ƒç”¨äº† calculate_bollinger_bands)
        bollinger_position = calculate_bollinger_bands(df_asc['value'])

        return {
            'RSI(14)': round(rsi_14_latest, 2) if not math.isnan(rsi_14_latest) else np.nan, # é”®åæ›´æ–°
            'RSI(6)': round(rsi_6_latest, 2) if not math.isnan(rsi_6_latest) else np.nan,   # æ–°å¢
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_position, 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI(14)': np.nan, 
            'RSI(6)': np.nan, # æ–°å¢RSI(6)
            'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 
            'å‡€å€¼/MA50': np.nan,
            'å‡€å€¼/MA250': np.nan, 
            'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯',
            'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯',
            'æœ€æ–°å‡€å€¼': np.nan,
            'å½“æ—¥è·Œå¹…': np.nan
        }

# --- è¿ç»­ä¸‹è·Œè®¡ç®— (å‡½æ•°é…ç½® 5/13) ---
def calculate_consecutive_drops(series):
    """
    è®¡ç®—å‡€å€¼åºåˆ—ä¸­æœ€å¤§çš„è¿ç»­ä¸‹è·Œå¤©æ•° (t < t-1)
    å‡è®¾ series æ˜¯æŒ‰æ—¶é—´å‡åºæ’åˆ—çš„ï¼ˆæœ€æ–°å€¼åœ¨æœ«å°¾ï¼‰ã€‚
    """
    try:
        if series.empty or len(series) < 2: return 0
        
        # 1. ç›´æ¥ä½¿ç”¨ series (å·²æ˜¯å‡åº)
        series_asc = series
        
        # 2. æ ‡è®°æ¯ä¸€å¤©ç›¸å¯¹äºå‰ä¸€å¤©æ˜¯å¦ä¸‹è·Œï¼ˆå½“å‰å€¼ < å‰å€¼ï¼‰
        # diff() è®¡ç®— t - t-1ã€‚å¦‚æœç»“æœ < 0ï¼Œåˆ™ä»£è¡¨ä¸‹è·Œã€‚
        # drops æ˜¯å¸ƒå°”æ•°ç»„ï¼ŒTrue ä»£è¡¨ä¸‹è·Œã€‚
        drops = (series_asc.diff() < 0).values
        
        max_drop_days = 0
        current_drop_days = 0
        
        # ä»ç¬¬äºŒä¸ªå…ƒç´ å¼€å§‹éå† (ç¬¬ä¸€ä¸ª diff æ˜¯ NaNï¼Œå·²ç»æ˜¯ False)
        for is_dropped in drops:
            if is_dropped: # å¦‚æœæ˜¯ä¸‹è·Œ (t < t-1)
                current_drop_days += 1
                max_drop_days = max(max_drop_days, current_drop_days)
            else: # å¦‚æœæ˜¯ä¸Šæ¶¨æˆ–æŒå¹³ (t >= t-1)
                current_drop_days = 0
        
        return max_drop_days
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

# --- æœ€å¤§å›æ’¤è®¡ç®— (å‡½æ•°é…ç½® 6/13) ---
def calculate_max_drawdown(series):
    """
    è®¡ç®—æœ€å¤§å›æ’¤
    å‡è®¾ series æ˜¯æŒ‰æ—¶é—´å‡åºæ’åˆ—çš„ï¼ˆæœ€æ–°å€¼åœ¨æœ«å°¾ï¼‰ã€‚
    """
    try:
        if series.empty: return 0.0
        
        # 1. è®¡ç®—ç´¯è®¡æœ€é«˜ç‚¹
        rolling_max = series.cummax()
        
        # 2. æœ€å¤§å›æ’¤ = (æœ€é«˜ç‚¹ - å½“å‰ç‚¹) / æœ€é«˜ç‚¹
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

# --- è¡ŒåŠ¨æç¤ºç”Ÿæˆ (å‡½æ•°é…ç½® 7/13) ---
def get_action_prompt(rsi_val, daily_drop_val, mdd_recent_month, max_drop_days_week):
    """
    æ ¹æ®æŠ€æœ¯æŒ‡æ ‡ç”ŸæˆåŸºç¡€è¡ŒåŠ¨æç¤ºï¼Œç§»é™¤ max_drop_days_week == 1 çš„å¹²æ‰°æ¡ä»¶ã€‚
    æ³¨æ„ï¼šrsi_val ä¼ å…¥çš„æ˜¯ RSI(14) çš„å€¼
    """
    
    # ä¼˜å…ˆç­›é€‰ï¼šä¸€ä¸ªæœˆå›æ’¤ >= 10% (HIGH_ELASTICITY_MIN_DRAWDOWN)
    if mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN:
        if pd.isna(rsi_val): return 'é«˜å›æ’¤è§‚å¯Ÿ (RSIæ•°æ®ç¼ºå¤±)'
        
        # P1 æå€¼è¶…å–
        if rsi_val <= EXTREME_RSI_THRESHOLD_P1:
            return f'ğŸŒŸ P1-æå€¼è¶…å– (RSI<={EXTREME_RSI_THRESHOLD_P1:.0f})'
        # P2 å¼ºåŠ›è¶…å–
        elif rsi_val <= STRONG_RSI_THRESHOLD_P2:
            return f'ğŸ”¥ P2-å¼ºåŠ›è¶…å– (RSI<={STRONG_RSI_THRESHOLD_P2:.0f})'
        else:
            return 'è§‚å¯Ÿä¸­ (RSIæœªè¶…å–)'
    
    # æ¬¡è¦ç­›é€‰ï¼šåŸºç¡€å›æ’¤ 6% <= å›æ’¤ < 10%
    if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
         return f'å…³æ³¨ (å›æ’¤ {mdd_recent_month:.2%})'
    
    return 'ä¸é€‚ç”¨ (æœªè¾¾åŸºç¡€å›æ’¤)'

# --- å•åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 8/13) ---
def analyze_single_fund(filepath):
    """
    åˆ†æå•åªåŸºé‡‘
    """
    fund_code = os.path.splitext(os.path.basename(filepath))[0]
    df = pd.DataFrame()

    try:
        # å°è¯•é»˜è®¤ UTF-8 ç¼–ç åŠ è½½
        df = pd.read_csv(filepath)
    except UnicodeDecodeError:
        try:
            # å°è¯• GBK ç¼–ç ï¼ˆè§£å†³ä¸­æ–‡ç¯å¢ƒä¹±ç é—®é¢˜ï¼‰
            df = pd.read_csv(filepath, encoding='gbk')
        except Exception as e:
            logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿç¼–ç æˆ–åŠ è½½é”™è¯¯: {e}")
            return None
    except Exception as e:
         logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”ŸåŠ è½½é”™è¯¯: {e}")
         return None

    try:
        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨ï¼Œéå‡€å€¼æ–‡ä»¶å°†ç›´æ¥è·³è¿‡
        if 'date' not in df.columns or 'net_value' not in df.columns:
            return None
            
        df['date'] = pd.to_datetime(df['date'])
        
        # ã€å·²ä¿®æ­£ã€‘å¼ºåˆ¶å‡åºæ’åˆ— (æœ€æ—©æ—¥æœŸåœ¨æœ€å‰é¢ï¼Œæœ€æ–°æ—¥æœŸåœ¨æœ€åé¢)
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        # ä¿æŒåŸå§‹è„šæœ¬é€»è¾‘ï¼šé‡å‘½ååˆ—
        df = df.rename(columns={'net_value': 'value'})
        
        is_valid, msg = validate_fund_data(df, fund_code)
        if not is_valid: 
             logging.warning(f"åŸºé‡‘ {fund_code} æ•°æ®æ— æ•ˆ: {msg}")
             return None
        
        # æˆªå–è¿‘ä¸€ä¸ªæœˆ/ä¸€å‘¨çš„æ•°æ®ï¼Œå› ä¸ºæ˜¯å‡åºï¼Œæ‰€ä»¥ç”¨ tail()
        df_recent_month = df['value'].tail(30)
        df_recent_week = df['value'].tail(5)
        
        mdd_recent_month = calculate_max_drawdown(df_recent_month)
        max_drop_days_week = calculate_consecutive_drops(df_recent_week)
        
        # calculate_technical_indicators ç°åœ¨æ¥æ”¶å‡åºçš„df
        tech_indicators = calculate_technical_indicators(df)
        
        action_prompt = get_action_prompt(
            tech_indicators.get('RSI(14)', np.nan), # ä½¿ç”¨ RSI(14)
            tech_indicators.get('å½“æ—¥è·Œå¹…', 0.0), 
            mdd_recent_month, 
            max_drop_days_week
        )
        
        # æ³¨æ„ï¼šè¿™é‡Œçš„æ¡ä»¶ç°åœ¨åªæ£€æŸ¥ MIN_MONTH_DRAWDOWN >= 6%
        if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
            return {
                'åŸºé‡‘ä»£ç ': fund_code,
                'æœ€å¤§å›æ’¤': mdd_recent_month,
                'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df['value'].tail(30)), # å†æ¬¡ä½¿ç”¨è¿‘ä¸€ä¸ªæœˆæ•°æ®
                'è¿‘ä¸€å‘¨è¿è·Œ': max_drop_days_week,
                **tech_indicators,
                'è¡ŒåŠ¨æç¤º': action_prompt
            }
        return None
    except Exception as e:
        # æ•è·åç»­å¤„ç†ä¸­çš„å…¶ä»–é”™è¯¯ (å¦‚è®¡ç®—é”™è¯¯)
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return None

# --- æ‰€æœ‰åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 9/13) ---
def analyze_all_funds(target_codes=None):
    """åˆ†ææ‰€æœ‰åŸºé‡‘æ•°æ®"""
    try:
        if target_codes:
            # ç›®æ ‡ä»£ç æ¨¡å¼ï¼šä» FUND_DATA_DIR ä¸­æŸ¥æ‰¾ç‰¹å®šæ–‡ä»¶
            csv_files = [os.path.join(FUND_DATA_DIR, f'{code}.csv') for code in target_codes if os.path.exists(os.path.join(FUND_DATA_DIR, f'{code}.csv'))]
        else:
            # æ˜ç¡®æŒ‡å®šæŸ¥æ‰¾ FUND_DATA_DIR ç›®å½•ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶
            csv_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
        
        if not csv_files:
            logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶")
            # å¦‚æœ FUND_DATA_DIR ä¸å­˜åœ¨ï¼Œåˆ™å°è¯•åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾ï¼Œå…¼å®¹ä¹‹å‰è¿è¡Œç¯å¢ƒ
            if FUND_DATA_DIR and not os.path.exists(FUND_DATA_DIR):
                logging.warning(f"ç›®å½• '{FUND_DATA_DIR}' ä¸å­˜åœ¨ï¼Œå°è¯•åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾...")
                csv_files = glob.glob('*.csv')
        
        if not csv_files:
             return []
            
        logging.info(f"æ‰¾åˆ° {len(csv_files)} ä¸ªåŸºé‡‘æ•°æ®æ–‡ä»¶ï¼Œå¼€å§‹åˆ†æ...")
        qualifying_funds = []
        for filepath in csv_files:
            result = analyze_single_fund(filepath)
            if result is not None:
                qualifying_funds.append(result)
        
        logging.info(f"åˆ†æå®Œæˆï¼Œå…±æ‰¾åˆ° {len(qualifying_funds)} åªç¬¦åˆåŸºç¡€é¢„è­¦æ¡ä»¶çš„åŸºé‡‘")
        return qualifying_funds
    except Exception as e:
        logging.error(f"åˆ†ææ‰€æœ‰åŸºé‡‘æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []

# --- æŠ€æœ¯å€¼æ ¼å¼åŒ– (å‡½æ•°é…ç½® 10/13) ---
def format_technical_value(value, format_type='percent'):
    """æ ¼å¼åŒ–æŠ€æœ¯æŒ‡æ ‡å€¼ç”¨äºæ˜¾ç¤º"""
    if pd.isna(value): return 'NaN'
    
    # report_daily_drop ç±»å‹ç›´æ¥æ˜¾ç¤ºå®é™…æ¶¨è·Œå¹…ï¼Œè´Ÿå·è¡¨ç¤ºä¸‹è·Œã€‚
    if format_type == 'report_daily_drop':
        # å¦‚æœæ˜¯è´Ÿå€¼ï¼ˆä¸‹è·Œï¼‰ï¼Œç”¨çº¢è‰²ç²—ä½“æ˜¾ç¤ºï¼›å¦‚æœæ˜¯æ­£å€¼ï¼ˆä¸Šæ¶¨ï¼‰ï¼Œç”¨ç»¿è‰²ç²—ä½“æ˜¾ç¤ºã€‚
        if value < 0:
            return f"**{value:.2%}**"
        elif value > 0:
            return f"{value:.2%}" # åŸå§‹æ²¡æœ‰é¢œè‰²ï¼Œä½†ä¹ æƒ¯ä¸Šæ˜¯ç»¿è‰²ï¼Œè¿™é‡Œä¿æŒåŸæ ·
        else:
            return "0.00%"
            
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

# --- è¡¨æ ¼è¡Œæ ¼å¼åŒ– (å‡½æ•°é…ç½® 11/13) ---
def format_table_row(index, row, table_part=1):
    """
    æ ¼å¼åŒ– Markdown è¡¨æ ¼è¡Œï¼ŒåŒ…å«é¢œè‰²/ç¬¦å·æ ‡è®°ï¼Œç¡®ä¿æ¸…æ™°åº¦ã€‚
    æ ¹æ® table_part è¾“å‡ºè¡¨çš„æŸä¸€éƒ¨åˆ†ï¼Œä»¥è§£å†³æ»šåŠ¨æ¡é—®é¢˜ã€‚
    """
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    # è®¡ç®—è¯•æ°´ä»·ï¼šå½“å‰å‡€å€¼ * (1 - 3%çš„è·Œå¹…)
    trial_price = latest_value * (1 - 0.03) 
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio_display = format_technical_value(row['MA50/MA250'], 'decimal2')
    
    # è¶‹åŠ¿é£é™©è­¦å‘Š
    if trend_display == 'å‘ä¸‹' and row['MA50/MA250'] < 0.95:
         trend_display = f"âš ï¸ **{trend_display}**"
         ma_ratio_display = f"âš ï¸ **{ma_ratio_display}**"
    elif pd.isna(row['MA50/MA250']) or row['MA50/MA250è¶‹åŠ¿'] == 'æ•°æ®ä¸è¶³':
        # æ•°æ®ä¸è¶³ 250 æ¡æ—¶ï¼Œè¿™äº›å­—æ®µä¼šæ˜¯ NaN æˆ– 'æ•°æ®ä¸è¶³'
        trend_display = "---"
        ma_ratio_display = "---"
    else:
        trend_display = f"**{trend_display}**"
        ma_ratio_display = f"**{ma_ratio_display}**"
        
    # æ­¤å¤„ä½¿ç”¨ä¿®æ­£åçš„ 'report_daily_drop'ï¼Œä¼šç›´æ¥æ˜¾ç¤ºå¦‚ -3.79%
    daily_drop_display = format_technical_value(row['å½“æ—¥è·Œå¹…'], 'report_daily_drop')


    if table_part == 1:
        # è¡¨æ ¼ 1 (7åˆ—): æ’å, åŸºé‡‘ä»£ç , æœ€å¤§å›æ’¤ (1M), å½“æ—¥æ¶¨è·Œå¹…, RSI(14), RSI(6), è¡ŒåŠ¨æç¤º - æ–°å¢RSI(6)
        return (
            f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
            f"{daily_drop_display} | **{row['RSI(14)']:.2f}** | **{row['RSI(6)']:.2f}** | **{row['è¡ŒåŠ¨æç¤º']}** |\n"
        )
    else:
        # è¡¨æ ¼ 2 (8åˆ—): åŸºé‡‘ä»£ç , MACDä¿¡å·, å¸ƒæ—å¸¦ä½ç½®, å‡€å€¼/MA50, MA50/MA250, è¶‹åŠ¿, å‡€å€¼/MA250, è¯•æ°´ä¹°ä»· (è·Œ3%)
        return (
            f"| `{row['åŸºé‡‘ä»£ç ']}` | {row['MACDä¿¡å·']} | {row['å¸ƒæ—å¸¦ä½ç½®']} | "
            f"{format_technical_value(row['å‡€å€¼/MA50'], 'decimal2')} | {ma_ratio_display} | {trend_display} | "
            f"{format_technical_value(row['å‡€å€¼/MA250'], 'decimal2') if not pd.isna(row['å‡€å€¼/MA250']) else '---'} | `{trial_price:.4f}` |\n"
        )

# --- æŠ¥å‘Šç”Ÿæˆ (å‡½æ•°é…ç½® 12/13) ---
def generate_report(results, timestamp_str):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Šã€‚
    """
    try:
        if not results:
            return (f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                    f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶çš„åŸºé‡‘ã€‚**")

        df_results = pd.DataFrame(results).sort_values(by='æœ€å¤§å›æ’¤', ascending=False).reset_index(drop=True)
        actual_total_count = len(results)

        report_parts = []
        report_parts.extend([
            f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            # LaTeX ç¬¦å·æ­£ç¡®è½¬ä¹‰
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{actual_total_count}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰ã€‚\n",
            f"**ç­–ç•¥æ›´æ–°ï¼šRSIç¬¬ä¸€ä¼˜å…ˆçº§é˜ˆå€¼ $\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$ï¼›ç¬¬äºŒä¼˜å…ˆçº§é˜ˆå€¼ $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$ã€‚**\n",
            f"\n---\n"
        ])

        # æ ¸å¿ƒç­›é€‰ï¼šé«˜å¼¹æ€§åŸºé‡‘
        df_base_elastic = df_results[
            (df_results['æœ€å¤§å›æ’¤'] >= HIGH_ELASTICITY_MIN_DRAWDOWN)
        ].copy()
        
        # ä¸ºäº†å…¼å®¹åŸå§‹è„šæœ¬çš„åˆ¤æ–­é€»è¾‘ï¼šå½“æ—¥è·Œå¹… >= 3% (å³ daily_drop <= -0.03)
        CRITICAL_DROP_INT = MIN_DAILY_DROP_PERCENT
        
        # P1Aï¼šå³æ—¶ææ…Œä¹°å…¥ (å½“æ—¥è·Œå¹… <= -3%)
        df_p1 = df_base_elastic[df_base_elastic['RSI(14)'] <= EXTREME_RSI_THRESHOLD_P1].copy() # ä½¿ç”¨ RSI(14)
        # åˆ¤æ–­ï¼šå½“æ—¥è·Œå¹… <= -0.03 (å³å®é™…è·Œå¹…å¤§äºç­‰äº 3%)
        # ä¿®æ­£å daily_drop < 0 ä»£è¡¨ä¸‹è·Œã€‚æ‰€ä»¥åˆ¤æ–­å¤§è·Œæ˜¯ daily_drop <= -CRITICAL_DROP_INT
        df_p1a = df_p1[df_p1['å½“æ—¥è·Œå¹…'] <= -CRITICAL_DROP_INT].copy() 
        # P1Bï¼šæŠ€æœ¯å…±æŒ¯å»ºä»“ (å½“æ—¥è·Œå¹… > -3%)
        df_p1b = df_p1[df_p1['å½“æ—¥è·Œå¹…'] > -CRITICAL_DROP_INT].copy()  
        
        # å®šä¹‰ä¸¤ä¸ªè¡¨æ ¼çš„å¤´éƒ¨å’Œå¯¹é½åˆ†éš”ç¬¦
        # è¡¨æ ¼ 1 (7åˆ—): æ’å, åŸºé‡‘ä»£ç , æœ€å¤§å›æ’¤ (1M), å½“æ—¥æ¶¨è·Œå¹…, RSI(14), RSI(6), è¡ŒåŠ¨æç¤º - æ›´æ–°
        TABLE_1_HEADER = f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥æ¶¨è·Œå¹…** | RSI(14) | **RSI(6)** | è¡ŒåŠ¨æç¤º |\n"
        TABLE_1_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
        
        # è¡¨æ ¼ 2 (8åˆ—): åŸºé‡‘ä»£ç , MACDä¿¡å·, å¸ƒæ—å¸¦ä½ç½®, å‡€å€¼/MA50, MA50/MA250, è¶‹åŠ¿, å‡€å€¼/MA250, è¯•æ°´ä¹°ä»· (è·Œ3%)
        TABLE_2_HEADER = f"| åŸºé‡‘ä»£ç  | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250** | **è¶‹åŠ¿** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) |\n"
        TABLE_2_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
        
        
        # ----------------------------------------------------
        # 1. ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šRSI <= 29.0
        # ----------------------------------------------------
        
        # --- æŠ¥å‘Š P1A ---
        if not df_p1a.empty:
            # ä¼˜å…ˆæŒ‰è·Œå¹…ä»å¤§åˆ°å°æ’åº (è´Ÿå€¼ç»å¯¹å€¼å¤§)
            df_p1a = df_p1a.sort_values(by=['å½“æ—¥è·Œå¹…', 'RSI(14)'], ascending=[True, True]).reset_index(drop=True)
            df_p1a.index = df_p1a.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ Aï¼šã€å³æ—¶ææ…Œä¹°å…¥ã€‘** ({len(df_p1a)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSIæåº¦è¶…å– ($\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$)** + **å½“æ—¥è·Œå¹… $\\le -{MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** å¸‚åœºææ…Œæ—¶å‡ºæ‰‹ï¼Œæœ¬é‡‘å……è¶³æ—¶åº”ä¼˜å…ˆé…ç½®ã€‚**ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
                TABLE_1_HEADER, # ä½¿ç”¨æ›´æ–°çš„å¤´éƒ¨
                TABLE_1_SEPARATOR # ä½¿ç”¨æ›´æ–°çš„åˆ†å‰²çº¿
            ])
            for index, row in df_p1a.iterrows():
                report_parts.append(format_table_row(index, row, table_part=1))
            
            report_parts.extend([
                "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
                TABLE_2_HEADER,
                TABLE_2_SEPARATOR
            ])
            for index, row in df_p1a.iterrows():
                report_parts.append(format_table_row(index, row, table_part=2))
            
            report_parts.append("\n---\n")

        # --- æŠ¥å‘Š P1B ---
        if not df_p1b.empty:
            df_p1b = df_p1b.sort_values(by=['RSI(14)', 'æœ€å¤§å›æ’¤'], ascending=[True, False]).reset_index(drop=True)
            df_p1b.index = df_p1b.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥‡ ç¬¬ä¸€ä¼˜å…ˆçº§ Bï¼šã€æŠ€æœ¯å…±æŒ¯å»ºä»“ã€‘** ({len(df_p1b)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSIæåº¦è¶…å– ($\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$)** + **å½“æ—¥è·Œå¹… $ > -{MIN_DAILY_DROP_PERCENT*100:.0f}%**\n",
                r"**çºªå¾‹ï¼š** æå€¼è¶…å–ï¼Œé€‚åˆåœ¨éå¤§è·Œæ—¥è¿›è¡Œå»ºä»“ã€‚**ï¼ˆç¬¬äºŒé«˜ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
                TABLE_1_HEADER, # ä½¿ç”¨æ›´æ–°çš„å¤´éƒ¨
                TABLE_1_SEPARATOR # ä½¿ç”¨æ›´æ–°çš„åˆ†å‰²çº¿
            ])
            for index, row in df_p1b.iterrows():
                report_parts.append(format_table_row(index, row, table_part=1))
                
            report_parts.extend([
                "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
                TABLE_2_HEADER,
                TABLE_2_SEPARATOR
            ])
            for index, row in df_p1b.iterrows():
                report_parts.append(format_table_row(index, row, table_part=2))
                
            report_parts.append("\n---\n")

        # ----------------------------------------------------
        # 2. ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼š29.0 < RSI <= 35.0
        # ----------------------------------------------------
        df_p2 = df_base_elastic[
            (df_base_elastic['RSI(14)'] > EXTREME_RSI_THRESHOLD_P1) & # ä½¿ç”¨ RSI(14)
            (df_base_elastic['RSI(14)'] <= STRONG_RSI_THRESHOLD_P2)   # ä½¿ç”¨ RSI(14)
        ].copy()

        if not df_p2.empty:
            df_p2 = df_p2.sort_values(by=['RSI(14)', 'æœ€å¤§å›æ’¤'], ascending=[True, False]).reset_index(drop=True)
            df_p2.index = df_p2.index + 1
            
            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± ã€‘** ({len(df_p2)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **å¼ºåŠ›è¶…å– ($>{EXTREME_RSI_THRESHOLD_P1:.0f}$ ä¸” $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$)**ã€‚\n",
                r"**çºªå¾‹ï¼š** æ¥è¿‘æå€¼ï¼Œæ˜¯è‰¯å¥½çš„è§‚å¯Ÿç›®æ ‡ï¼Œä½†éœ€ç­‰å¾… RSI è¿›ä¸€æ­¥ä¸‹è¡Œæˆ–è¶‹åŠ¿ç¡®ç«‹ã€‚**ï¼ˆç¬¬ä¸‰ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
                TABLE_1_HEADER, # ä½¿ç”¨æ›´æ–°çš„å¤´éƒ¨
                TABLE_1_SEPARATOR # ä½¿ç”¨æ›´æ–°çš„åˆ†å‰²çº¿
            ])

            for index, row in df_p2.iterrows():
                report_parts.append(format_table_row(index, row, table_part=1))
                
            report_parts.extend([
                "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
                TABLE_2_HEADER,
                TABLE_2_SEPARATOR
            ])
            for index, row in df_p2.iterrows():
                report_parts.append(format_table_row(index, row, table_part=2))
                
            report_parts.append("\n---\n")
        else:
            report_parts.extend([
                f"\n## **ğŸ¥ˆ ç¬¬äºŒä¼˜å…ˆçº§ï¼šã€å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± ã€‘**\n\n",
                f"æ²¡æœ‰åŸºé‡‘æ»¡è¶³ **é•¿æœŸè¶…è·Œ** ä¸” **RSI ($>{EXTREME_RSI_THRESHOLD_P1:.0f}$ ä¸” $\\le {STRONG_RSI_THRESHOLD_P2:.0f}$)** çš„æ¡ä»¶ã€‚" + "\n\n",
                f"---\n"
            ])


        # 3. ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šæ‰©å±•è§‚å¯Ÿæ±  (RSI > 35.0)
        df_p3 = df_base_elastic[
            df_base_elastic['RSI(14)'] > STRONG_RSI_THRESHOLD_P2 # ä½¿ç”¨ RSI(14)
        ].copy()

        if not df_p3.empty:
            df_p3 = df_p3.sort_values(by='æœ€å¤§å›æ’¤', ascending=False).reset_index(drop=True)
            df_p3.index = df_p3.index + 1

            report_parts.extend([
                f"\n## **ğŸ¥‰ ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šã€æ‰©å±•è§‚å¯Ÿæ± ã€‘** ({len(df_p3)}åª)\n\n",
                f"**æ¡ä»¶ï¼š** é•¿æœŸè¶…è·Œ + **RSI $>{STRONG_RSI_THRESHOLD_P2:.0f}$ (æœªè¾¾å¼ºåŠ›è¶…å–)**ã€‚\n",
                r"**çºªå¾‹ï¼š** é£é™©è¾ƒé«˜ï¼Œä»…ä½œä¸ºè§‚å¯Ÿå’Œå¤‡é€‰ï¼Œç­‰å¾… RSI è¿›ä¸€æ­¥è¿›å…¥è¶…å–åŒºã€‚**ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰**" + "\n\n",
                "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
                TABLE_1_HEADER, # ä½¿ç”¨æ›´æ–°çš„å¤´éƒ¨
                TABLE_1_SEPARATOR # ä½¿ç”¨æ›´æ–°çš„åˆ†å‰²çº¿
            ])

            for index, row in df_p3.iterrows():
                report_parts.append(format_table_row(index, row, table_part=1))
                
            report_parts.extend([
                "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
                TABLE_2_HEADER,
                TABLE_2_SEPARATOR
            ])
            for index, row in df_p3.iterrows():
                report_parts.append(format_table_row(index, row, table_part=2))

            report_parts.append("\n---\n")
        
        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ï¼ˆåŒ…å«è¡Œä¸šé£é™©æç¤ºï¼‰
        report_parts.extend([
            "\n---\n",
            f"## **âš ï¸ å¼ºåŒ–æ‰§è¡Œçºªå¾‹ï¼šé£æ§ä¸è¡Œä¸šå®¡æŸ¥**\n\n",
            f"**1. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼ˆMA50/MA250 å†³å®šèƒ½å¦ä¹°ï¼‰ï¼š**\n",
            f"    * **MA50/MA250 $\\ge 0.95$ ä¸” è¶‹åŠ¿æ–¹å‘ä¸º 'å‘ä¸Š' æˆ– 'å¹³ç¨³'** çš„åŸºé‡‘ï¼Œè§†ä¸º **è¶‹åŠ¿å¥åº·**ï¼Œå…è®¸è¯•æ°´ã€‚\n",
            f"    * **è‹¥åŸºé‡‘è¶‹åŠ¿æ˜¾ç¤º âš ï¸ å‘ä¸‹ï¼Œæˆ– MA50/MA250 $< 0.95$ï¼Œ** åˆ™è¡¨æ˜é•¿æœŸå¤„äºç†Šå¸‚é€šé“ï¼Œ**å¿…é¡»æ”¾å¼ƒ**ï¼Œæ— è®ºçŸ­æœŸè¶…è·Œæœ‰å¤šä¸¥é‡ã€‚\n",
            f"    * **ã€æ–°åŸºé‡‘æç¤ºã€‘**ï¼šå¯¹äºæ•°æ®ä¸è¶³ 250 æ¡çš„åŸºé‡‘ï¼ŒMA50/MA250 ç›¸å…³æŒ‡æ ‡å°†æ˜¾ç¤º **'---'**ï¼Œéœ€ç»“åˆå…¶ä»–æŒ‡æ ‡å’Œäººå·¥å®¡æŸ¥æ¥åˆ¤æ–­ã€‚\n",
            f"**2. ğŸ” äººå·¥è¡Œä¸šä¸Kçº¿å®¡æŸ¥ï¼ˆæ’é™¤æ¥é£åˆ€é£é™©ï¼‰ï¼š**\n",
            r"    * **åœ¨ä¹°å…¥å‰ï¼Œå¿…é¡»æŸ¥é˜…åŸºé‡‘é‡ä»“è¡Œä¸šã€‚** å¦‚æœåŸºé‡‘å±äºè¿‘æœŸï¼ˆå¦‚è¿‘ 3-6 ä¸ªæœˆï¼‰**æ¶¨å¹…å·¨å¤§ã€ä¼°å€¼è¿‡é«˜**çš„æ¿å—ï¼ˆä¾‹å¦‚ï¼šéƒ¨åˆ†AIã€åŠå¯¼ä½“ï¼‰ï¼Œåˆ™å³ä½¿æŠ€æœ¯è¶…å–ï¼Œä¹Ÿåº”è§†ä¸º**é«˜é£é™©å›è°ƒ**ï¼Œå»ºè®®**æ”¾å¼ƒ**æˆ–**å¤§å¹…ç¼©å‡**è¯•æ°´ä»“ä½ã€‚\n",
            r"    * **åŒæ—¶å¤æ ¸ K çº¿å›¾ï¼š** ç¡®è®¤å½“å‰ä»·æ ¼æ˜¯å¦è·ç¦»**è¿‘åŠå¹´å†å²é«˜ç‚¹**å¤ªè¿‘ã€‚è‹¥æ˜¯ï¼Œåˆ™é£é™©é«˜ã€‚\n",
            f"**3. I çº§è¯•æ°´å»ºä»“ï¼ˆRSIæå€¼ç­–ç•¥ï¼‰ï¼š**\n",
            f"    * ä»…å½“åŸºé‡‘æ»¡è¶³ï¼š**è¶‹åŠ¿å¥åº·** + **å‡€å€¼/MA50 $\\le 1.0$** + **RSI $\\le {EXTREME_RSI_THRESHOLD_P1:.0f}$** æ—¶ï¼Œæ‰è¿›è¡Œ $\\mathbf{{I}}$ çº§è¯•æ°´ã€‚\n",
            f"**4. é£é™©æ§åˆ¶ï¼š**\n",
            f"    * ä¸¥æ ¼æ­¢æŸçº¿ï¼šå¹³å‡æˆæœ¬ä»·**è·Œå¹…è¾¾åˆ° 8%-10%**ï¼Œç«‹å³æ¸…ä»“æ­¢æŸã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

# --- ä¸»å‡½æ•° (å‡½æ•°é…ç½® 13/13) ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            # ä½¿ç”¨å¸¦æ—¶åŒºçš„å½“å‰æ—¶é—´
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
        
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    # è¯·ç¡®ä¿ 'fund_data' ç›®å½•å­˜åœ¨ï¼Œä¸”å…¶ä¸­åŒ…å«ä»¥åŸºé‡‘ä»£ç å‘½åçš„ CSV æ–‡ä»¶ (date, net_value)
    success = main()
    print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚æ‰€æœ‰é…ç½®å’Œå‡½æ•°å‡å·²å®Œæ•´ä¿ç•™ã€‚")
