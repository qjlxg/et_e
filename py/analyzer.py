import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- V5.0 ç­–ç•¥æ‰€éœ€é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_MONTH_DRAWDOWN = 0.06 # V5.0 éœ‡è¡å¸‚æ ¸å¿ƒè§¦å‘ (å›æ’¤ >= 5%, æ­¤å¤„ä½¿ç”¨ 6% è¿‘ä¼¼ç­›é€‰)
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15 # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (15%)
MIN_DAILY_DROP_PERCENT = 0.03 # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report_v5'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 # ç½‘æ ¼çº§ï¼šRSI(14) æå€¼è¶…å–
STRONG_RSI_THRESHOLD_P2 = 35.0 # å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± 
SHORT_TERM_RSI_EXTREME = 20.0 # RSI(6)çš„æå€¼è¶…å–é˜ˆå€¼

# --- è®¾ç½®æ—¥å¿— (å‡½æ•°é…ç½® 1/13) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- éªŒè¯æ•°æ® (å‡½æ•°é…ç½® 2/13) ---
def validate_fund_data(df, fund_code):
    """éªŒè¯åŸºé‡‘æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡"""
    if df.empty: return False, "æ•°æ®ä¸ºç©º"
    if 'value' not in df.columns: return False, "ç¼ºå°‘å‡€å€¼åˆ—"
    # ã€å·²ä¿ç•™ã€‘æœ€å°æ•°æ®è¦æ±‚ä¸º 60
    if len(df) < 60: return False, f"æ•°æ®ä¸è¶³60æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
    if (df['value'] <= 0).any(): return False, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
    return True, "æ•°æ®æœ‰æ•ˆ"

# --- å¸ƒæ—å¸¦è®¡ç®— (å‡½æ•°é…ç½® 3/13) ---
def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        range_band = latest_upper - latest_lower
        if range_band == 0:
            return "è½¨é“ä¸­é—´" 
            
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (å‡½æ•°é…ç½® 4/13) ---
def calculate_technical_indicators(df):
    """
    è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡ (RSI(14), RSI(6), MACD, MA, è¶‹åŠ¿ç­‰)
    """
    df_asc = df.copy()

    try:
        if 'value' not in df_asc.columns or len(df_asc) < 60:
            return {
                'RSI(14)': np.nan, 
                'RSI(6)': np.nan, 
                'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 
                'å‡€å€¼/MA50': np.nan,
                'å‡€å€¼/MA250': np.nan, 
                'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³',
                'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 
                'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
            }

        delta = df_asc['value'].diff()

        # 1. RSI (14) & (6)
        for window in [14, 6]:
            gain = (delta.where(delta > 0, 0)).rolling(window=window, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=window, min_periods=1).mean()
            rs = gain / loss.replace(0, np.nan) 
            df_asc[f'RSI_{window}'] = 100 - (100 / (1 + rs))

        rsi_14_latest = df_asc['RSI_14'].iloc[-1]
        rsi_6_latest = df_asc['RSI_6'].iloc[-1]
        
        # 2. MACD
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            is_golden_cross = macd_latest > signal_latest and macd_prev < signal_prev
            # is_death_cross = macd_latest < signal_latest and macd_prev > signal_prev # V5.0 ä¸ä½¿ç”¨æ­»å‰
            
            if is_golden_cross:
                if macd_latest > 0: macd_signal = 'å¼ºåŠ¿é‡‘å‰'
                elif macd_latest < 0: macd_signal = 'å¼±åŠ¿é‡‘å‰'
                else: macd_signal = 'é‡‘å‰'
        # elif is_death_cross: # æ’é™¤æ­»å‰é€»è¾‘ï¼Œåªå…³æ³¨åº•éƒ¨é‡‘å‰
        #     ...
        
        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean() 
        
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]
        
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan
        
        if len(df_asc) < 250:
            net_to_ma250 = np.nan
            ma50_to_ma250 = np.nan
            trend_direction = 'æ•°æ®ä¸è¶³'
        else:
            net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            
            trend_direction = 'æ•°æ®ä¸è¶³'
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(20).dropna()
            if len(recent_ratio) >= 5:
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                if slope > 0.001: trend_direction = 'å‘ä¸Š'
                elif slope < -0.001: trend_direction = 'å‘ä¸‹'
                else: trend_direction = 'å¹³ç¨³'
        
        # 4. å½“æ—¥æ¶¨è·Œå¹…
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                daily_drop = (value_latest - value_t_minus_1) / value_t_minus_1
                
        # 5. å¸ƒæ—å¸¦ä½ç½®
        bollinger_position = calculate_bollinger_bands(df_asc['value'])

        return {
            'RSI(14)': round(rsi_14_latest, 2) if not math.isnan(rsi_14_latest) else np.nan, 
            'RSI(6)': round(rsi_6_latest, 2) if not math.isnan(rsi_6_latest) else np.nan,     
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_position, 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 
            'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯', 'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯',
            'æœ€æ–°å‡€å€¼': np.nan, 'å½“æ—¥è·Œå¹…': np.nan
        }

# --- è¿ç»­ä¸‹è·Œè®¡ç®— (å‡½æ•°é…ç½® 5/13) ---
def calculate_consecutive_drops(series):
    # é€»è¾‘ä¸å˜
    try:
        if series.empty or len(series) < 2: return 0
        
        drops = (series.diff() < 0).values
        max_drop_days = 0
        current_drop_days = 0
        
        for is_dropped in drops:
            if is_dropped: 
                current_drop_days += 1
                max_drop_days = max(max_drop_days, current_drop_days)
            else: 
                current_drop_days = 0
        
        return max_drop_days
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

# --- æœ€å¤§å›æ’¤è®¡ç®— (å‡½æ•°é…ç½® 6/13) ---
def calculate_max_drawdown(series):
    # é€»è¾‘ä¸å˜
    try:
        if series.empty: return 0.0
        
        rolling_max = series.cummax()
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

# --- V5.0 è¡ŒåŠ¨ä¿¡å·ç”Ÿæˆ (å‡½æ•°é…ç½® 7/13) ---
def generate_v5_action_signal(row):
    """
    æ ¹æ® V5.0 ç­–ç•¥çš„æŠ€æœ¯è¦æ±‚ï¼Œç”Ÿæˆè¯•ä»“ä¿¡å·ã€‚
    æ³¨æ„ï¼šæœ¬è„šæœ¬æ— æ³•è·å–å®è§‚ç¯å¢ƒï¼ˆç‰›/ç†Š/éœ‡è¡ï¼‰ï¼Œä»…æä¾›æŠ€æœ¯ä¿¡å·å…±æŒ¯æƒ…å†µã€‚
    """
    rsi_14_val = row.get('RSI(14)', np.nan)
    rsi_6_val = row.get('RSI(6)', np.nan)
    macd_signal = row.get('MACDä¿¡å·', '')
    bollinger_position = row.get('å¸ƒæ—å¸¦ä½ç½®', '')
    mdd_recent_month = row.get('æœ€å¤§å›æ’¤', 0.0)
    daily_drop_val = row.get('å½“æ—¥è·Œå¹…', 0.0)
    
    signals = []

    # --- V5.0 ç½‘æ ¼çº§ / æå€¼è¶…å–ä¿¡å· (æœ€é«˜ä¼˜å…ˆçº§ï¼Œç‹¬ç«‹äºå§¿æ€) ---
    if not pd.isna(rsi_14_val) and rsi_14_val <= EXTREME_RSI_THRESHOLD_P1:
        rsi_display = f"RSI14:{rsi_14_val:.1f}"
        if rsi_6_val <= SHORT_TERM_RSI_EXTREME:
            # æå€¼è¶…å– + çŸ­æœŸè¶…å–
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯({rsi_display})")
        elif daily_drop_val <= -MIN_DAILY_DROP_PERCENT:
            # æå€¼è¶…å– + å½“æ—¥å¤§è·Œ
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼+ææ…Œ({rsi_display})")
        else:
            # ä»…æå€¼è¶…å–
            signals.append(f"ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼({rsi_display})")

    # --- V5.0 æ¸¸å‡»å§¿æ€ (éœ‡è¡å¸‚) ä¿¡å· ---
    # æ ¸å¿ƒè§¦å‘ï¼šå›æ’¤ >= 6% (MIN_MONTH_DRAWDOWN)
    if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
        # æŠ€æœ¯è¾…åŠ©ï¼šå¸ƒæ—å¸¦è§¦åŠä¸‹è½¨ (V5.0 æ¸¸å‡»å§¿æ€çš„æœ€ä½³è¯•ä»“ä¿¡å·)
        if bollinger_position in ["**ä¸‹è½¨ä¸‹æ–¹**", "ä¸‹è½¨é™„è¿‘"]:
            signals.append("ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘è§¦åŠBOLLä¸‹è½¨")
        # æ¬¡çº§ä¿¡å·ï¼šå›æ’¤è¾¾åˆ° 10% (é«˜å¼¹æ€§è¦æ±‚)
        elif mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN:
            signals.append("ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘é«˜å¼¹æ€§å›æ’¤è¾¾æ ‡")
        elif not signals:
            signals.append("ã€éœ‡è¡-å…³æ³¨ã€‘åŸºç¡€å›æ’¤è¾¾æ ‡")

    # --- V5.0 é˜²å¾¡å§¿æ€ (ç†Šå¸‚) ä¿¡å· ---
    # æ ¸å¿ƒè§¦å‘ï¼šMACD åº•èƒŒç¦»ï¼ˆæ­¤å¤„ç”¨å¼±åŠ¿é‡‘å‰ä½œä¸ºåå¼¹å¯åŠ¨çš„è¿‘ä¼¼ä¿¡å·ï¼‰
    if macd_signal == 'å¼±åŠ¿é‡‘å‰':
        signals.append("ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘MACDå¼±é‡‘å‰")
        
    # --- V5.0 è¿›æ”»å§¿æ€ (ç‰›å¸‚) è¿‡æ»¤å™¨æ£€æŸ¥ ---
    if not pd.isna(rsi_14_val) and rsi_14_val > 70.0:
        signals.append("ğŸš«ã€ç‰›å¸‚è¿‡æ»¤å™¨ã€‘RSI(14)>70")
        
    # æœ€ç»ˆè¾“å‡º
    if not signals:
        return 'ç­‰å¾…ä¿¡å· (æœªè¾¾åŸºç¡€å›æ’¤)'
        
    return ' | '.join(signals)


# --- éå†å¹¶åˆ†ææ‰€æœ‰åŸºé‡‘ (å‡½æ•°é…ç½® 8/13 - è¡¥å…¨çš„å‡½æ•°) ---
def analyze_all_funds():
    """éå† FUND_DATA_DIR ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶å¹¶åˆ†æ"""
    fund_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
    results = []
    
    if not fund_files:
        logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°ä»»ä½•åŸºé‡‘æ•°æ®æ–‡ä»¶ã€‚")
        return results

    for filepath in fund_files:
        fund_result = analyze_single_fund(filepath)
        if fund_result:
            results.append(fund_result)
            
    logging.info(f"æ‰€æœ‰åŸºé‡‘åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªåŸºé‡‘ç¬¦åˆæŠ¥å‘Šæ¡ä»¶ã€‚")
    return results

# --- å•åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 9/13 - åŸæ–‡çš„ 8/13) ---
def analyze_single_fund(filepath):
    # ... (åŠ è½½æ•°æ®ï¼ŒéªŒè¯æ•°æ®çš„é€»è¾‘ä¿æŒä¸å˜)
    fund_code = os.path.splitext(os.path.basename(filepath))[0]
    df = pd.DataFrame()

    try:
        # å°è¯•ä½¿ç”¨ UTF-8
        df = pd.read_csv(filepath)
    except UnicodeDecodeError:
        try:
            # å°è¯•ä½¿ç”¨ GBK
            df = pd.read_csv(filepath, encoding='gbk')
        except Exception as e:
            logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿç¼–ç æˆ–åŠ è½½é”™è¯¯: {e}")
            return None
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”ŸåŠ è½½é”™è¯¯: {e}")
        return None

    try:
        if 'date' not in df.columns or 'net_value' not in df.columns:
            # å°è¯•å¦ä¸€ç§åˆ—åå…¼å®¹
            if 'Date' in df.columns and 'NetValue' in df.columns:
                 df = df.rename(columns={'Date': 'date', 'NetValue': 'net_value'})
            else:
                logging.warning(f"åŸºé‡‘ {fund_code} ç¼ºå°‘ 'date' æˆ– 'net_value' åˆ—ã€‚")
                return None
            
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        
        is_valid, msg = validate_fund_data(df, fund_code)
        if not is_valid: 
            logging.warning(f"åŸºé‡‘ {fund_code} æ•°æ®æ— æ•ˆ: {msg}")
            return None
        
        df_recent_month = df['value'].tail(30)
        df_recent_week = df['value'].tail(5)
        
        mdd_recent_month = calculate_max_drawdown(df_recent_month)
        max_drop_days_week = calculate_consecutive_drops(df_recent_week)
        
        tech_indicators = calculate_technical_indicators(df)
        
        # *** æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨ V5.0 ä¿¡å·ç”Ÿæˆå‡½æ•° ***
        # åˆ›å»ºä¸€ä¸ªåŒ…å«æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡å’Œå›æ’¤çš„è¡Œå¯¹è±¡
        row_data = {**tech_indicators, 'æœ€å¤§å›æ’¤': mdd_recent_month, 'å½“æ—¥è·Œå¹…': tech_indicators['å½“æ—¥è·Œå¹…']}
        
        action_prompt = generate_v5_action_signal(row_data) # ä½¿ç”¨æ–°çš„ä¿¡å·ç”Ÿæˆå‡½æ•°
        
        # æ³¨æ„ï¼šè¿™é‡Œçš„æ¡ä»¶ä¿æŒä¸å˜ï¼Œåªè¦å›æ’¤ >= 6% å°±çº³å…¥æŠ¥å‘Š
        if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
            return {
                'åŸºé‡‘ä»£ç ': fund_code,
                'æœ€å¤§å›æ’¤': mdd_recent_month,
                'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df['value'].tail(30)),
                'è¿‘ä¸€å‘¨è¿è·Œ': max_drop_days_week,
                **tech_indicators,
                'è¡ŒåŠ¨æç¤º': action_prompt
            }
        return None
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return None


# --- æŠ€æœ¯å€¼æ ¼å¼åŒ– (å‡½æ•°é…ç½® 10/13) ---
def format_technical_value(value, format_type='percent'):
    # ä¿æŒä¸å˜
    if pd.isna(value): return 'NaN'
    
    if format_type == 'report_daily_drop':
        if value < 0:
            return f"**{value:.2%}**"
        elif value > 0:
            return f"{value:.2%}" 
        else:
            return "0.00%"
            
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

# --- è¡¨æ ¼è¡Œæ ¼å¼åŒ– (å‡½æ•°é…ç½® 11/13) ---
def format_table_row(index, row, table_part=1):
    # ä¿æŒä¸å˜ï¼Œä½†ç§»é™¤äº†é¢œè‰²/ç¬¦å·æ ‡è®°ï¼Œè®©æŠ¥å‘Šä¸­çš„ä¿¡å·å­—æ®µä¸»å¯¼
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    trial_price = latest_value * (1 - 0.03) # é¢„ä¼°è·Œ3%æ—¶çš„è¯•æ°´ä»·æ ¼
    
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio = row.get('MA50/MA250')
    ma_ratio_display = format_technical_value(ma_ratio, 'decimal2')
    
    # è¶‹åŠ¿é£é™©è­¦å‘Š
    is_data_insufficient = pd.isna(ma_ratio) or trend_display == 'æ•°æ®ä¸è¶³'
    
    if is_data_insufficient:
        trend_status = "---"
    elif trend_display == 'å‘ä¸‹' or (not pd.isna(ma_ratio) and ma_ratio < 0.95): 
        trend_status = f"âš ï¸ **{trend_display}** ({ma_ratio_display})"
    else:
        trend_status = f"**{trend_display}** ({ma_ratio_display})"
        
    daily_drop_display = format_technical_value(row['å½“æ—¥è·Œå¹…'], 'report_daily_drop')


    if table_part == 1:
        # è¡¨æ ¼ 1 (7åˆ—): æ’å, åŸºé‡‘ä»£ç , æœ€å¤§å›æ’¤ (1M), å½“æ—¥æ¶¨è·Œå¹…, RSI(14), RSI(6), è¡ŒåŠ¨æç¤º
        return (
            f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
            f"{daily_drop_display} | **{row['RSI(14)']:.2f}** | **{row['RSI(6)']:.2f}** | **{row['è¡ŒåŠ¨æç¤º']}** |\n"
        )
    else:
        # è¡¨æ ¼ 2 (8åˆ—): åŸºé‡‘ä»£ç , MACDä¿¡å·, å¸ƒæ—å¸¦ä½ç½®, å‡€å€¼/MA50, MA50/MA250è¶‹åŠ¿å¥åº·åº¦, å‡€å€¼/MA250, è¯•æ°´ä¹°ä»·
        return (
            f"| `{row['åŸºé‡‘ä»£ç ']}` | {row['MACDä¿¡å·']} | {row['å¸ƒæ—å¸¦ä½ç½®']} | "
            f"{format_technical_value(row['å‡€å€¼/MA50'], 'decimal2')} | {trend_status} | "
            f"{format_technical_value(row['å‡€å€¼/MA250'], 'decimal2') if not pd.isna(row['å‡€å€¼/MA250']) else '---'} | `{trial_price:.4f}` |\n"
        )

# --- æŠ¥å‘Šç”Ÿæˆ (å‡½æ•°é…ç½® 12/13) ---
def generate_report(results, timestamp_str):
    """
    ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Šï¼Œå¹¶æŒ‰ V5.0 ä¿¡å·å¼ºåº¦æ’åºã€‚
    """
    try:
        if not results:
            return (f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                    f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶çš„åŸºé‡‘ã€‚**")

        df_results = pd.DataFrame(results).reset_index(drop=True)
        actual_total_count = len(results)

        report_parts = []
        report_parts.extend([
            f"# åŸºé‡‘ V5.0 ç­–ç•¥é€‰è‚¡æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{actual_total_count}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\ge {MIN_MONTH_DRAWDOWN*100:.0f}\%$ï¼‰ã€‚\n",
            f"**å†³ç­–é‡ç‚¹ï¼š** **V5.0 ç­–ç•¥å¯åŠ¨å¿…é¡»å…ˆè¿›è¡Œå®è§‚ç¯å¢ƒåˆ¤æ–­ï¼** æœ¬æŠ¥å‘Šä»…æä¾›åŸºé‡‘çš„æŠ€æœ¯å…±æŒ¯ä¿¡å·ã€‚\n",
            f"\n---\n"
        ])
        
        # å®šä¹‰ V5.0 ä¼˜å…ˆçº§ï¼š
        # 1. ç½‘æ ¼çº§æå€¼ï¼šç”¨äº V4.4 ç½‘æ ¼è¡¥ä»“æˆ– V1.0 æè½»ä»“è¯•æ°´
        # 2. éœ‡è¡-é«˜å¸ï¼šç”¨äº V1.0 æ¸¸å‡»å§¿æ€çš„æœ€ä½³å¯åŠ¨ä¿¡å·
        # 3. é˜²å¾¡-åå¼¹ï¼šç”¨äº V1.0 é˜²å¾¡å§¿æ€çš„å¯åŠ¨ä¿¡å·
        # 4. å…³æ³¨/é¢„è­¦ï¼šç­‰å¾…ä¿¡å·ç¡®è®¤
        
        # ä¸ºæŠ¥å‘Šæ’åºï¼Œä¼˜å…ˆçº§ï¼šç½‘æ ¼æå€¼ > BOLLä¸‹è½¨ > MACDå¼±é‡‘å‰ > é«˜å¼¹æ€§å›æ’¤ > åŸºç¡€å›æ’¤
        df_results['signal_score'] = 0
        df_results.loc[df_results['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ’¥ã€ç½‘æ ¼çº§ã€‘'), 'signal_score'] = 5
        df_results.loc[df_results['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘'), 'signal_score'] = 4
        df_results.loc[df_results['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘'), 'signal_score'] = 3
        df_results.loc[df_results['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘'), 'signal_score'] = 2
        df_results.loc[df_results['è¡ŒåŠ¨æç¤º'].str.contains('ã€éœ‡è¡-å…³æ³¨ã€‘'), 'signal_score'] = 1

        df_sorted = df_results.sort_values(by=['signal_score', 'æœ€å¤§å›æ’¤'], ascending=[False, False]).reset_index(drop=True)
        
        
        TABLE_1_HEADER = f"| æ’å | åŸºé‡‘ä»£ç  | æœ€å¤§å›æ’¤ (1M) | **å½“æ—¥æ¶¨è·Œå¹…** | RSI(14) | **RSI(6)** | V5.0 ä¿¡å· |\n"
        TABLE_1_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
        TABLE_2_HEADER = f"| åŸºé‡‘ä»£ç  | MACDä¿¡å· | å¸ƒæ—å¸¦ä½ç½® | å‡€å€¼/MA50 | **MA50/MA250å¥åº·åº¦** | å‡€å€¼/MA250 | è¯•æ°´ä¹°ä»· (è·Œ3%) |\n"
        TABLE_2_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
        
        
        for score, df_group in df_sorted.groupby('signal_score'):
            if score == 5:
                title = "ğŸš€ I. ã€ç½‘æ ¼çº§/æå€¼è¯•ä»“ã€‘ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰"
                description = "æ»¡è¶³æå€¼è¶…å–æ¡ä»¶ï¼Œæ˜¯ V4.4 ç­–ç•¥çš„ç†æƒ³è¡¥ä»“ç›®æ ‡ï¼Œæˆ– V1.0 æè½»ä»“è¯•æ°´ç›®æ ‡ã€‚"
            elif score == 4:
                title = "ğŸ¯ II. ã€éœ‡è¡-é«˜å¸ã€‘ï¼ˆV1.0 æ¸¸å‡»å§¿æ€æœ€ä½³å¯åŠ¨ï¼‰"
                description = "å›æ’¤è¾¾æ ‡ä¸”æŠ€æœ¯è§¦åº•ï¼ˆBOLLä¸‹è½¨ï¼‰ï¼Œæ˜¯ V1.0 æ¸¸å‡»å§¿æ€ï¼ˆéœ‡è¡å¸‚ï¼‰çš„æœ€ä½³è¯•ä»“ç›®æ ‡ã€‚"
            elif score == 3:
                title = "ğŸ›¡ï¸ III. ã€é˜²å¾¡-åå¼¹ã€‘ï¼ˆV1.0 é˜²å¾¡å§¿æ€å¯åŠ¨ï¼‰"
                description = "MACDå‡ºç°åº•éƒ¨åå¼¹ä¿¡å·ï¼Œæ˜¯ V1.0 é˜²å¾¡å§¿æ€ï¼ˆç†Šå¸‚ï¼‰çš„å¯åŠ¨å‚è€ƒã€‚"
            elif score == 2 or score == 1:
                title = "ğŸ” IV. ã€æŒç»­è§‚å¯Ÿ/é¢„è­¦æ± ã€‘"
                description = "å›æ’¤è¾¾æ ‡ï¼Œä½†æŠ€æœ¯ä¿¡å·è¾ƒå¼±ï¼Œéœ€ç­‰å¾…ä¿¡å·è¿›ä¸€æ­¥ç¡®è®¤æˆ–ç¯å¢ƒå˜åŒ–ã€‚"
            elif score == 0:
                continue # è·³è¿‡æœªè¾¾æ ‡çš„åŸºé‡‘

            current_index = 0
            df_group = df_group.sort_values(by='æœ€å¤§å›æ’¤', ascending=False)
            
            report_parts.extend([
                f"\n## {title} ({len(df_group)}åª)\n\n",
                f"**çºªå¾‹ï¼š** {description}\n\n",
                "### æ ¸å¿ƒæŒ‡æ ‡ (1/2)\n",
                TABLE_1_HEADER,
                TABLE_1_SEPARATOR
            ])

            for _, row in df_group.iterrows():
                current_index += 1
                report_parts.append(format_table_row(current_index, row, table_part=1))
                
            report_parts.extend([
                "\n### è¶‹åŠ¿ä¸æŠ€æœ¯ç»†èŠ‚ (2/2)\n",
                TABLE_2_HEADER,
                TABLE_2_SEPARATOR
            ])

            # åœ¨è¿™é‡Œé‡ç½®ç´¢å¼•ï¼Œä»¥ä¾¿ Table 2 ä»ç„¶èƒ½æ­£ç¡®åŒ¹é… Table 1 çš„åˆ†ç»„
            current_index = 0 
            for _, row in df_group.iterrows():
                current_index += 1
                report_parts.append(format_table_row(current_index, row, table_part=2))
                
            report_parts.append("\n---\n")

        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ï¼ˆæœ€åå†æ¬¡å¼ºè°ƒ V5.0 çš„å®è§‚åˆ¤æ–­ï¼‰
        report_parts.extend([
            "\n---\n",
            f"## **âš ï¸ V5.0 å®è§‚ç¯å¢ƒä¸è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸**\n\n",
            f"**1. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼ˆMA50/MA250 å†³å®šèƒ½å¦ä¹°ï¼‰ï¼š**\n",
            f"Â  Â  * **è¶‹åŠ¿å¥åº·**ï¼šMA50/MA250 $\\ge 0.95$ ä¸” è¶‹åŠ¿æ–¹å‘ä¸º 'å‘ä¸Š' æˆ– 'å¹³ç¨³'ï¼Œå…è®¸è¯•ä»“ã€‚\n",
            f"Â  Â  * **è¶‹åŠ¿ä¸å¥åº·**ï¼šè‹¥åŸºé‡‘æ˜¾ç¤º **âš ï¸ å‘ä¸‹**ï¼Œæˆ– MA50/MA250 $< 0.95$ï¼Œ**å¿…é¡»æ”¾å¼ƒè¯•ä»“**ã€‚\n",
            f"**2. ğŸŒ V1.0 è¯•ä»“å§¿æ€ç¡®è®¤ï¼ˆå®è§‚ç¯å¢ƒå†³å®šä»“ä½ï¼‰ï¼š**\n",
            f"Â  Â  * **åœ¨æ‰§è¡Œè¯•ä»“å‰ï¼Œå¿…é¡»æ‰‹åŠ¨åˆ¤æ–­å®è§‚ç¯å¢ƒï¼ˆç‰›å¸‚/éœ‡è¡å¸‚/ç†Šå¸‚ï¼‰ï¼Œå¹¶æ ¹æ® V5.0 æ‰‹å†Œç¡®å®šä»“ä½ï¼ˆ5%, 10%, 20%ï¼‰å’Œæ´»æ€§åŒºé—´**ã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

# --- ä¸»å‡½æ•° (å‡½æ•°é…ç½® 13/13) ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except Exception: # æ•è·æ›´é€šç”¨çš„å¼‚å¸¸
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
            
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        # ç¡®ä¿ FUND_DATA_DIR å­˜åœ¨
        if not os.path.isdir(FUND_DATA_DIR):
            logging.error(f"åŸºé‡‘æ•°æ®ç›®å½• '{FUND_DATA_DIR}' ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºè¯¥ç›®å½•å¹¶æ”¾å…¥ CSV æ–‡ä»¶ã€‚")
            return False

        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    success = main()
    if success:
        print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚å·²æ›´æ–°ä¸º V5.0 ç­–ç•¥é€‰è‚¡é€»è¾‘ï¼ŒæŠ¥å‘Šè¾“å‡ºæ›´èšç„¦äº V5.0 è¯•ä»“/è¡¥ä»“ä¿¡å·ã€‚")
    else:
        print("è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ fund_analysis.log æ–‡ä»¶ä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
