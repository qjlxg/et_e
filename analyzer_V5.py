import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- V5.0 ç­–ç•¥æ‰€éœ€é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_MONTH_DRAWDOWN = 0.06 # V5.0 éœ‡è¡å¸‚æ ¸å¿ƒè§¦å‘ (å›æ’¤ >= 6%)
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15 # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (15%)
MIN_DAILY_DROP_PERCENT = 0.03 # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report_v5_merged_table'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 # ç½‘æ ¼çº§ï¼šRSI(14) æå€¼è¶…å–
STRONG_RSI_THRESHOLD_P2 = 35.0 # å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± 
SHORT_TERM_RSI_EXTREME = 20.0 # RSI(6)çš„æå€¼è¶…å–é˜ˆå€¼
TREND_HEALTH_THRESHOLD = 0.9 # MA50/MA250 å¥åº·åº¦é˜ˆå€¼ (0.9)
MIN_BUY_SIGNAL_SCORE = 3.7 # æœ€ä½ä¿¡å·åˆ†æ•°
TREND_SLOPE_THRESHOLD = 0.005 # è¶‹åŠ¿æ‹Ÿåˆæ–œç‡é˜ˆå€¼

# --- è®¾ç½®æ—¥å¿— (1/15) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯ (2/15) ---
def load_and_preprocess_data(filepath, fund_code):
    """
    åŠ è½½ã€é¢„å¤„ç†å’ŒéªŒè¯åŸºé‡‘æ•°æ®ã€‚
    æ”¯æŒè¡¨å¤´ï¼šdate, net_value, cumulative_net_value, daily_growth_rate...
    """
    try:
        try:
            df = pd.read_csv(filepath)
        except UnicodeDecodeError:
            df = pd.read_csv(filepath, encoding='gbk')
        
        # ç»Ÿä¸€åˆ—åæ˜ å°„é€»è¾‘ (é’ˆå¯¹ç”¨æˆ·æä¾›çš„æ–°è¡¨å¤´)
        column_map = {
            'date': 'date',
            'net_value': 'value',
            'Date': 'date',
            'NetValue': 'value'
        }
        
        # å¦‚æœåˆ—åä¸­å­˜åœ¨ net_valueï¼Œåˆ™å°†å…¶é‡å‘½åä¸ºåˆ†æç”¨çš„ value
        current_cols = df.columns.tolist()
        rename_dict = {}
        for old_col, new_col in column_map.items():
            if old_col in current_cols:
                rename_dict[old_col] = new_col
        
        df = df.rename(columns=rename_dict)
        
        # æ£€æŸ¥å…³é”®åˆ—
        if 'date' not in df.columns or 'value' not in df.columns:
            logging.warning(f"åŸºé‡‘ {fund_code} ç¼ºå°‘ 'date' æˆ– 'net_value' åˆ—ã€‚ç°æœ‰çš„åˆ—ä¸º: {df.columns.tolist()}")
            return None, "ç¼ºå°‘å…³é”®åˆ—"
            
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        
        if df.empty: return None, "æ•°æ®ä¸ºç©º"
        if len(df) < 60: return None, f"æ•°æ®ä¸è¶³60æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
        if (df['value'] <= 0).any(): return None, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
        
        return df, "æ•°æ®æœ‰æ•ˆ"
        
    except Exception as e:
        logging.error(f"åŠ è½½åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None, f"åŠ è½½é”™è¯¯: {e}"

# --- å¸ƒæ—å¸¦è®¡ç®— (3/15) ---
def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        range_band = latest_upper - latest_lower
        if range_band <= 1e-6:
            return "è½¨é“ä¸­é—´" 
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (4/15) ---
def calculate_technical_indicators(df):
    """è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡"""
    df_asc = df.copy()
    try:
        if 'value' not in df_asc.columns or len(df_asc) < 60:
             return {
                'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 
                'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³', 'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 
                'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
             }

        delta = df_asc['value'].diff()
        for window in [14, 6]:
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.ewm(span=window, adjust=False, min_periods=1).mean()
            avg_loss = loss.ewm(span=window, adjust=False, min_periods=1).mean()
            rs = avg_gain / avg_loss.replace(0, 1e-10) 
            df_asc[f'RSI_{window}'] = 100 - (100 / (1 + rs))

        rsi_14_latest = df_asc['RSI_14'].iloc[-1]
        rsi_6_latest = df_asc['RSI_6'].iloc[-1]
        
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            if macd_latest > signal_latest and macd_prev <= signal_prev:
                macd_signal = 'å¼ºåŠ¿é‡‘å‰' if macd_latest > 0 else 'å¼±åŠ¿é‡‘å‰'
            elif macd_latest < signal_latest and macd_prev >= signal_prev:
                macd_signal = 'æ­»å‰' 
        
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean() 
        value_latest = df_asc['value'].iloc[-1]
        net_to_ma50 = value_latest / df_asc['MA50'].iloc[-1] if df_asc['MA50'].iloc[-1] != 0 else np.nan

        if len(df_asc) < 250:
            net_to_ma250, ma50_to_ma250, trend_direction = np.nan, np.nan, 'æ•°æ®ä¸è¶³'
        else:
            ma50_l, ma250_l = df_asc['MA50'].iloc[-1], df_asc['MA250'].iloc[-1]
            net_to_ma250 = value_latest / ma250_l if ma250_l != 0 else np.nan
            ma50_to_ma250 = ma50_l / ma250_l if ma250_l != 0 else np.nan
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(50).dropna() 
            if len(recent_ratio) >= 5:
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                trend_direction = 'å‘ä¸Š' if slope > TREND_SLOPE_THRESHOLD else ('å‘ä¸‹' if slope < -TREND_SLOPE_THRESHOLD else 'å¹³ç¨³')
            else: trend_direction = 'æ•°æ®ä¸è¶³'
        
        daily_drop = 0.0
        if len(df_asc) >= 2:
            v_prev = df_asc['value'].iloc[-2]
            if v_prev > 0: daily_drop = (value_latest - v_prev) / v_prev
            
        return {
            'RSI(14)': round(rsi_14_latest, 2) if not math.isnan(rsi_14_latest) else np.nan, 
            'RSI(6)': round(rsi_6_latest, 2) if not math.isnan(rsi_6_latest) else np.nan,     
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': calculate_bollinger_bands(df_asc['value']), 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }
    except Exception as e:
        logging.error(f"æŠ€æœ¯æŒ‡æ ‡é”™è¯¯: {e}")
        return {'RSI(14)': np.nan, 'MACDä¿¡å·': 'é”™è¯¯', 'æœ€æ–°å‡€å€¼': np.nan, 'å½“æ—¥è·Œå¹…': np.nan, 'MA50/MA250è¶‹åŠ¿': 'é”™è¯¯', 'å¸ƒæ—å¸¦ä½ç½®': 'é”™è¯¯'}

# --- è¿ç»­ä¸‹è·Œè®¡ç®— (5/15) ---
def calculate_consecutive_drops(series):
    try:
        if series.empty or len(series) < 2: return 0
        drops = (series.diff() < 0).values
        count = 0
        for is_dropped in reversed(drops[1:]):
            if is_dropped: count += 1
            else: break
        return count
    except: return 0

# --- æœ€å¤§å›æ’¤è®¡ç®— (6/15) ---
def calculate_max_drawdown(series):
    try:
        if series.empty: return 0.0
        rolling_max = series.cummax()
        return ((rolling_max - series) / rolling_max).max()
    except: return 0.0

# --- å–å‡º/æ­¢æŸä¿¡å· (7/15) ---
def generate_exit_signal(row):
    rsi_14, macd, mdd = row.get('RSI(14)', np.nan), row.get('MACDä¿¡å·', ''), row.get('æœ€å¤§å›æ’¤', 0.0)
    sigs = []
    if not pd.isna(rsi_14) and rsi_14 > 70.0: sigs.append("ğŸš« æ­¢ç›ˆï¼šRSI(14) è¿‡ä¹°")
    if macd == 'æ­»å‰': sigs.append("ğŸš« æ­¢ç›ˆ/æ­¢æŸï¼šMACDæ­»å‰")
    if mdd > 0.10: sigs.append(f"ğŸ›‘ æ­¢æŸï¼šå›æ’¤è¶… 10% ({mdd:.2%})")
    return ' | '.join(sigs) if sigs else "æŒæœ‰"

# --- V5.0 è¡ŒåŠ¨ä¿¡å· (8/15) ---
def generate_v5_action_signal(row):
    rsi14, rsi6, macd, boll, mdd, drop, condrop = row.get('RSI(14)'), row.get('RSI(6)'), row.get('MACDä¿¡å·'), row.get('å¸ƒæ—å¸¦ä½ç½®'), row.get('æœ€å¤§å›æ’¤', 0), row.get('å½“æ—¥è·Œå¹…', 0), row.get('è¿‘10æ—¥è¿è·Œ', 0)
    sigs = []
    if not pd.isna(rsi14) and rsi14 <= EXTREME_RSI_THRESHOLD_P1:
        if rsi6 <= SHORT_TERM_RSI_EXTREME: sigs.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯(RSI14:{rsi14:.1f})")
        elif drop <= -MIN_DAILY_DROP_PERCENT: sigs.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼+ææ…Œ(RSI14:{rsi14:.1f})")
        else: sigs.append(f"ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼(RSI14:{rsi14:.1f})")
    if mdd >= MIN_MONTH_DRAWDOWN:
        if condrop >= 5 and not any('ç½‘æ ¼çº§' in s for s in sigs): sigs.append("âœ¨ã€éœ‡è¡-è¿è·Œã€‘è¿è·Œ5æ—¥+é«˜å›æ’¤") 
        if boll in ["**ä¸‹è½¨ä¸‹æ–¹**", "ä¸‹è½¨é™„è¿‘"]: sigs.append("ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘è§¦åŠBOLLä¸‹è½¨")
        elif mdd >= HIGH_ELASTICITY_MIN_DRAWDOWN: sigs.append("ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘é«˜å¼¹æ€§å›æ’¤è¾¾æ ‡")
        elif not sigs: sigs.append("ã€éœ‡è¡-å…³æ³¨ã€‘åŸºç¡€å›æ’¤è¾¾æ ‡")
    if macd == 'å¼±åŠ¿é‡‘å‰': sigs.append("ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘MACDå¼±é‡‘å‰")
    if not pd.isna(rsi14) and rsi14 > 70.0: sigs.append("ğŸš«ã€ç‰›å¸‚è¿‡æ»¤å™¨ã€‘RSI(14)>70")
    return ' | '.join(sigs) if sigs else 'ç­‰å¾…ä¿¡å· (æœªè¾¾åŸºç¡€å›æ’¤)'

# --- åˆ†æé€»è¾‘ (9-10/15) ---
def analyze_all_funds():
    files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
    results = []
    for f in files:
        res = analyze_single_fund(f)
        if res: results.append(res)
    return results

def analyze_single_fund(filepath):
    code = os.path.splitext(os.path.basename(filepath))[0]
    df, msg = load_and_preprocess_data(filepath, code)
    if df is None: return None
    try:
        latest_date = df['date'].iloc[-1]
        df_recent = df[df['date'] >= (latest_date - pd.DateOffset(months=1))]['value']
        mdd = calculate_max_drawdown(df_recent) if len(df_recent) >= 2 else 0.0
        tech = calculate_technical_indicators(df)
        con_drop = calculate_consecutive_drops(df['value'].tail(10))
        row = {**tech, 'æœ€å¤§å›æ’¤': mdd, 'è¿‘10æ—¥è¿è·Œ': con_drop}
        if not pd.isna(tech['æœ€æ–°å‡€å€¼']):
            return {'åŸºé‡‘ä»£ç ': code, 'æœ€å¤§å›æ’¤': mdd, 'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df['value']), 'è¿‘10æ—¥è¿è·Œ': con_drop, **tech, 'è¡ŒåŠ¨æç¤º': generate_v5_action_signal(row), 'é€€å‡ºæç¤º': generate_exit_signal(row)}
        return None
    except: return None

# --- æ ¼å¼åŒ–ä¸æŠ¥å‘Š (11-14/15) ---
def format_technical_value(val, fmt='percent'):
    if pd.isna(val): return '---'
    if fmt == 'report_daily_drop': return f"**{val:.2%}**" if val < 0 else f"{val:.2%}"
    if fmt == 'percent': return f"{val:.2%}"
    return f"{val:.2f}"

def format_table_row(idx, row):
    trial_price = row.get('æœ€æ–°å‡€å€¼', 1.0) * 0.97
    trend, ratio = row['MA50/MA250è¶‹åŠ¿'], row.get('MA50/MA250')
    if pd.isna(ratio) or trend == 'æ•°æ®ä¸è¶³': ts = "---"
    elif trend == 'å‘ä¸‹' or ratio < TREND_HEALTH_THRESHOLD: ts = f"âš ï¸ **{trend}** ({ratio:.2f})"
    else: ts = f"**{trend}** ({ratio:.2f})"
    
    rsi_disp = f"**{row['RSI(14)']:.2f}**" if not pd.isna(row['RSI(14)']) and row['RSI(14)'] <= STRONG_RSI_THRESHOLD_P2 else f"{row['RSI(14)']:.2f}"
    v5_sig = f"ğŸš« **æ­¢æŸå¦å†³** | {row['è¡ŒåŠ¨æç¤º']}" if "ğŸ›‘ æ­¢æŸï¼š" in row['é€€å‡ºæç¤º'] else f"**{row['è¡ŒåŠ¨æç¤º']}**"
    
    return (f"| {idx} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
            f"{format_technical_value(row['å½“æ—¥è·Œå¹…'], 'report_daily_drop')} | {rsi_disp} | {v5_sig} | "
            f"**{row['é€€å‡ºæç¤º']}** | {ts} | `{trial_price:.4f}` |\n")

def generate_merged_table(df_group):
    header = "| æ’å | åŸºé‡‘ä»£ç  | **æœ€å¤§å›æ’¤ (1M)** | **å½“æ—¥è·Œå¹…** | RSI(14) | **V5.0 ä¿¡å·** | **é€€å‡ºæç¤º** | MA50/MA250å¥åº·åº¦ | è¯•æ°´ä¹°ä»· (è·Œ3%) |\n"
    sep = "| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n"
    parts = ["### ç»¼åˆæŠ€æœ¯åˆ†æè¡¨\n", header, sep]
    for i, (_, row) in enumerate(df_group.iterrows(), 1):
        parts.append(format_table_row(i, row))
    parts.append("\n---\n")
    return "".join(parts)

def generate_report(results, ts_str):
    if not results: return f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({ts_str})\n\n**æ— æ•°æ®**"
    df = pd.DataFrame(results)
    df_f = df[df['æœ€å¤§å›æ’¤'] >= MIN_MONTH_DRAWDOWN].copy()
    if df_f.empty: return f"# åŸºé‡‘æŠ¥å‘Š ({ts_str})\n\n**æ— è§¦å‘å›æ’¤æ¡ä»¶çš„åŸºé‡‘**"

    # è¯„åˆ†é€»è¾‘
    score_map = {'ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯': 5.0, 'ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼': 4.5, 'ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼': 4.5, 'ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘': 4.0, 'âœ¨ã€éœ‡è¡-è¿è·Œã€‘': 3.5, 'ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘': 3.0, 'ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘': 2.0, 'ã€éœ‡è¡-å…³æ³¨ã€‘': 1.0}
    df_f['signal_score'] = df_f['è¡ŒåŠ¨æç¤º'].apply(lambda x: max([v for k, v in score_map.items() if k in x] + [0]))
    df_f['trend_score'] = df_f.apply(lambda r: 0 if r['MA50/MA250è¶‹åŠ¿'] == 'å‘ä¸‹' or r.get('MA50/MA250', 1) < TREND_HEALTH_THRESHOLD else 100, axis=1)
    df_f['is_stop_loss'] = np.where(df_f['æœ€å¤§å›æ’¤'] > 0.10, 1, 0)
    
    df_buy = df_f[(df_f['trend_score'] == 100) & (df_f['signal_score'] >= MIN_BUY_SIGNAL_SCORE)].sort_values(['is_stop_loss', 'signal_score', 'æœ€å¤§å›æ’¤'], ascending=[True, False, False])
    df_i_buyable = df_buy[df_buy['is_stop_loss'] == 0]
    df_ii_rejected = df_buy[df_buy['is_stop_loss'] == 1]
    df_iv = df_f[df_f['trend_score'] == 0].sort_values(['æœ€å¤§å›æ’¤'], ascending=False)

    report = [f"# åŸºé‡‘ V5.0 ç­–ç•¥æŠ¥å‘Š ({ts_str})\n\n", "## åˆ†ææ€»ç»“\n\n", f"å‘ç° **{len(df_f)}** åªåŸºé‡‘å…¥é€‰ã€‚\n", f"**{len(df_i_buyable)}** åªå¯è¯•ä»“ã€‚\n\n---\n"]
    if not df_i_buyable.empty:
        report.append(f"## ğŸ¥‡ I.1 ã€æœ€é«˜ä¼˜å…ˆçº§/å¯è¯•ä»“ã€‘ ({len(df_i_buyable)}åª)\n")
        report.append(generate_merged_table(df_i_buyable))
    if not df_ii_rejected.empty:
        report.append(f"## ğŸš« I.2 ã€è¶‹åŠ¿å¥åº·ä½†æ­¢æŸå¦å†³ã€‘ ({len(df_ii_rejected)}åª)\n")
        report.append(generate_merged_table(df_ii_rejected))
    if not df_iv.empty:
        report.append(f"## âŒ IV. ã€è¶‹åŠ¿ä¸å¥åº·ã€‘ ({len(df_iv)}åª)\n")
        report.append(generate_merged_table(df_iv))
    
    report.append("\n---\n## **âœ… æ ¸å¿ƒå†³ç­–çºªå¾‹**\n1. ä¼˜å…ˆ I.1 ç»„ã€‚\n2. è¶‹åŠ¿å‘ä¸‹å¿…é¡»æ”¾å¼ƒã€‚\n")
    return "".join(report)

# --- ä¸»å‡½æ•° (15/15) ---
def main():
    setup_logging()
    tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(tz)
    ts_file, ts_rep = now.strftime('%Y%m%d_%H%M%S'), now.strftime('%Y-%m-%d %H:%M:%S')
    os.makedirs(now.strftime('%Y%m'), exist_ok=True)
    report_path = os.path.join(now.strftime('%Y%m'), f"{REPORT_BASE_NAME}_{ts_file}.md")
    
    if not os.path.isdir(FUND_DATA_DIR):
        os.makedirs(FUND_DATA_DIR, exist_ok=True)
        return False

    results = analyze_all_funds()
    content = generate_report(results, ts_rep)
    with open(report_path, 'w', encoding='utf-8') as f: f.write(content)
    logging.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    return True

if __name__ == '__main__':
    if main(): print("è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚å·²å…¼å®¹æ–°è¡¨å¤´å¹¶æ›´æ–°æŠ¥å‘Šã€‚")
    else: print("æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚")