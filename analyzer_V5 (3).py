import pandas as pd
import glob
import os
import numpy as np
from datetime import datetime
import pytz
import logging
import math

# --- V5.0 ç­–ç•¥æ‰€éœ€é…ç½®å‚æ•° ---
FUND_DATA_DIR = 'fund_data'
MIN_MONTH_DRAWDOWN = 0.06 # V5.0 éœ‡è¡å¸‚æ ¸å¿ƒè§¦å‘ (å›æ’¤ >= 6%)
HIGH_ELASTICITY_MIN_DRAWDOWN = 0.15 # é«˜å¼¹æ€§ç­–ç•¥çš„åŸºç¡€å›æ’¤è¦æ±‚ (15%)
MIN_DAILY_DROP_PERCENT = 0.03 # å½“æ—¥å¤§è·Œçš„å®šä¹‰ (3%)
REPORT_BASE_NAME = 'fund_warning_report_v5_merged_table'

# --- æ ¸å¿ƒé˜ˆå€¼è°ƒæ•´ ---
EXTREME_RSI_THRESHOLD_P1 = 29.0 # ç½‘æ ¼çº§ï¼šRSI(14) æå€¼è¶…å–
STRONG_RSI_THRESHOLD_P2 = 35.0 # å¼ºåŠ›è¶…å–è§‚å¯Ÿæ± 
SHORT_TERM_RSI_EXTREME = 20.0 # RSI(6)çš„æå€¼è¶…å–é˜ˆå€¼
TREND_HEALTH_THRESHOLD = 0.9 # MA50/MA250 å¥åº·åº¦é˜ˆå€¼ (0.9)
MIN_BUY_SIGNAL_SCORE = 3.7 # æœ€ä½ä¿¡å·åˆ†æ•° (æ ¹æ®è®¨è®ºï¼Œå¼ºä¿¡å·æœ€ä½åˆ†è®¾ä¸º3.7)
TREND_SLOPE_THRESHOLD = 0.005 # è¶‹åŠ¿æ‹Ÿåˆæ–œç‡é˜ˆå€¼

# --- è®¾ç½®æ—¥å¿— (å‡½æ•°é…ç½® 1/15) ---
def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fund_analysis.log', encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

# --- æ•°æ®é¢„å¤„ç†å’ŒéªŒè¯ (å‡½æ•°é…ç½® 2/15) ---
def load_and_preprocess_data(filepath, fund_code):
    """
    åŠ è½½ã€é¢„å¤„ç†å’ŒéªŒè¯åŸºé‡‘æ•°æ®ã€‚
    """
    try:
        try:
            df = pd.read_csv(filepath)
        except UnicodeDecodeError:
            df = pd.read_csv(filepath, encoding='gbk')
        
        # ç»Ÿä¸€åˆ—å
        if 'date' not in df.columns or 'net_value' not in df.columns:
            if 'Date' in df.columns and 'NetValue' in df.columns:
                 df = df.rename(columns={'Date': 'date', 'NetValue': 'net_value'})
            else:
                logging.warning(f"åŸºé‡‘ {fund_code} ç¼ºå°‘ 'date' æˆ– 'net_value' åˆ—ã€‚")
                return None, "ç¼ºå°‘å…³é”®åˆ—"
            
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
        df = df.rename(columns={'net_value': 'value'})
        
        if df.empty: return None, "æ•°æ®ä¸ºç©º"
        if 'value' not in df.columns: return None, "ç¼ºå°‘å‡€å€¼åˆ—"
        if len(df) < 60: return None, f"æ•°æ®ä¸è¶³60æ¡ï¼Œå½“å‰åªæœ‰{len(df)}æ¡"
        if (df['value'] <= 0).any(): return None, "å­˜åœ¨æ— æ•ˆå‡€å€¼(<=0)"
        
        return df, "æ•°æ®æœ‰æ•ˆ"
        
    except Exception as e:
        logging.error(f"åŠ è½½åŸºé‡‘ {fund_code} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return None, f"åŠ è½½é”™è¯¯: {e}"

# --- å¸ƒæ—å¸¦è®¡ç®— (å‡½æ•°é…ç½® 3/15) ---
def calculate_bollinger_bands(series, window=20):
    """è®¡ç®—å¸ƒæ—å¸¦ä½ç½®"""
    if len(series) < window:
        return "æ•°æ®ä¸è¶³"
    
    df_temp = pd.DataFrame({'value': series.values})
    df_temp['MA20'] = df_temp['value'].rolling(window=window).mean()
    df_temp['STD20'] = df_temp['value'].rolling(window=window).std()
    
    if df_temp['STD20'].iloc[-1] == 0:
        return "æ³¢åŠ¨æå°"
        
    df_temp['Upper Band'] = df_temp['MA20'] + (df_temp['STD20'] * 2)
    df_temp['Lower Band'] = df_temp['MA20'] - (df_temp['STD20'] * 2)
    
    latest_value = df_temp['value'].iloc[-1]
    latest_lower = df_temp['Lower Band'].iloc[-1]
    latest_upper = df_temp['Upper Band'].iloc[-1]
    
    if pd.isna(latest_lower) or pd.isna(latest_upper):
        return "æ•°æ®ä¸è¶³"
        
    if latest_value <= latest_lower:
        return "**ä¸‹è½¨ä¸‹æ–¹**" 
    elif latest_value >= latest_upper:
        return "**ä¸Šè½¨ä¸Šæ–¹**" 
    else:
        range_band = latest_upper - latest_lower
        
        if range_band <= 1e-6:
            return "è½¨é“ä¸­é—´" 
            
        position = (latest_value - latest_lower) / range_band
        if position < 0.2:
            return "ä¸‹è½¨é™„è¿‘"
        elif position > 0.8:
            return "ä¸Šè½¨é™„è¿‘"
        else:
            return "è½¨é“ä¸­é—´"

# --- æŠ€æœ¯æŒ‡æ ‡è®¡ç®— (å‡½æ•°é…ç½® 4/15) ---
def calculate_technical_indicators(df):
    """
    è®¡ç®—åŸºé‡‘å‡€å€¼çš„å®Œæ•´æŠ€æœ¯æŒ‡æ ‡
    RSI ä¿®æ­£ï¼šä½¿ç”¨ EMA å¹³æ»‘ Gain/Loss
    """
    df_asc = df.copy()

    try:
        if 'value' not in df_asc.columns or len(df_asc) < 60:
             return {
                'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'æ•°æ®ä¸è¶³', 
                'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
                'MA50/MA250è¶‹åŠ¿': 'æ•°æ®ä¸è¶³', 'å¸ƒæ—å¸¦ä½ç½®': 'æ•°æ®ä¸è¶³', 
                'æœ€æ–°å‡€å€¼': df_asc['value'].iloc[-1] if not df_asc.empty else np.nan,
                'å½“æ—¥è·Œå¹…': np.nan
             }

        delta = df_asc['value'].diff()

        # 1. RSI (14) & (6) - ä¿®æ­£ä¸ºä½¿ç”¨ EMA å¹³æ»‘
        for window in [14, 6]:
            # åˆ†ç¦»æ¶¨è·Œ
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            
            # ä½¿ç”¨ EMA å¹³æ»‘ Gain/Loss
            avg_gain = gain.ewm(span=window, adjust=False, min_periods=1).mean()
            avg_loss = loss.ewm(span=window, adjust=False, min_periods=1).mean()
            
            # é¿å… RSI é™¤é›¶é”™è¯¯
            rs = avg_gain / avg_loss.replace(0, 1e-10) 
            df_asc[f'RSI_{window}'] = 100 - (100 / (1 + rs))

        rsi_14_latest = df_asc['RSI_14'].iloc[-1]
        rsi_6_latest = df_asc['RSI_6'].iloc[-1]
        
        # 2. MACD 
        ema_12 = df_asc['value'].ewm(span=12, adjust=False).mean()
        ema_26 = df_asc['value'].ewm(span=26, adjust=False).mean()
        df_asc['MACD'] = ema_12 - ema_26
        df_asc['Signal'] = df_asc['MACD'].ewm(span=9, adjust=False).mean()
        
        macd_latest = df_asc['MACD'].iloc[-1]
        signal_latest = df_asc['Signal'].iloc[-1]
        macd_prev = df_asc['MACD'].iloc[-2] if len(df_asc) >= 2 else np.nan
        signal_prev = df_asc['Signal'].iloc[-2] if len(df_asc) >= 2 else np.nan
        
        macd_signal = 'è§‚å¯Ÿ'
        if not np.isnan(macd_prev) and not np.isnan(signal_prev):
            is_golden_cross = macd_latest > signal_latest and macd_prev <= signal_prev
            is_dead_cross = macd_latest < signal_latest and macd_prev >= signal_prev 
            
            if is_golden_cross:
                if macd_latest > 0: macd_signal = 'å¼ºåŠ¿é‡‘å‰'
                elif macd_latest < 0: macd_signal = 'å¼±åŠ¿é‡‘å‰'
                else: macd_signal = 'é‡‘å‰'
            elif is_dead_cross:
                macd_signal = 'æ­»å‰' 
        
        # 3. ç§»åŠ¨å¹³å‡çº¿å’Œè¶‹åŠ¿åˆ†æ
        df_asc['MA50'] = df_asc['value'].rolling(window=50, min_periods=1).mean()
        df_asc['MA250'] = df_asc['value'].rolling(window=250, min_periods=1).mean() 
        
        ma50_latest = df_asc['MA50'].iloc[-1]
        ma250_latest = df_asc['MA250'].iloc[-1]
        value_latest = df_asc['value'].iloc[-1]
        
        net_to_ma50 = value_latest / ma50_latest if ma50_latest and ma50_latest != 0 else np.nan

        if len(df_asc) < 250:
            net_to_ma250 = np.nan
            ma50_to_ma250 = np.nan
            trend_direction = 'æ•°æ®ä¸è¶³'
        else:
            net_to_ma250 = value_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            ma50_to_ma250 = ma50_latest / ma250_latest if ma250_latest and ma250_latest != 0 else np.nan
            
            trend_direction = 'æ•°æ®ä¸è¶³'
            recent_ratio = (df_asc['MA50'] / df_asc['MA250']).tail(50).dropna() 
            
            if len(recent_ratio) >= 5:
                # æ‹ŸåˆMA50/MA250æ¯”å€¼çš„æ–œç‡
                slope = np.polyfit(np.arange(len(recent_ratio)), recent_ratio.values, 1)[0]
                if slope > TREND_SLOPE_THRESHOLD: trend_direction = 'å‘ä¸Š'
                elif slope < -TREND_SLOPE_THRESHOLD: trend_direction = 'å‘ä¸‹'
                else: trend_direction = 'å¹³ç¨³'
        
        # 4. å½“æ—¥æ¶¨è·Œå¹…
        daily_drop = 0.0
        if len(df_asc) >= 2:
            value_t_minus_1 = df_asc['value'].iloc[-2]
            if value_t_minus_1 > 0:
                daily_drop = (value_latest - value_t_minus_1) / value_t_minus_1
            
        # 5. å¸ƒæ—å¸¦ä½ç½®
        bollinger_position = calculate_bollinger_bands(df_asc['value'])

        return {
            'RSI(14)': round(rsi_14_latest, 2) if not math.isnan(rsi_14_latest) else np.nan, 
            'RSI(6)': round(rsi_6_latest, 2) if not math.isnan(rsi_6_latest) else np.nan,     
            'MACDä¿¡å·': macd_signal,
            'å‡€å€¼/MA50': round(net_to_ma50, 2) if not math.isnan(net_to_ma50) else np.nan,
            'å‡€å€¼/MA250': round(net_to_ma250, 2) if not math.isnan(net_to_ma250) else np.nan, 
            'MA50/MA250': round(ma50_to_ma250, 2) if not math.isnan(ma50_to_ma250) else np.nan, 
            'MA50/MA250è¶‹åŠ¿': trend_direction,
            'å¸ƒæ—å¸¦ä½ç½®': bollinger_position, 
            'æœ€æ–°å‡€å€¼': round(value_latest, 4) if not math.isnan(value_latest) else np.nan,
            'å½“æ—¥è·Œå¹…': round(daily_drop, 4) 
        }

    except Exception as e:
        logging.error(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return {
            'RSI(14)': np.nan, 'RSI(6)': np.nan, 'MACDä¿¡å·': 'è®¡ç®—é”™è¯¯', 
            'å‡€å€¼/MA50': np.nan, 'å‡€å€¼/MA250': np.nan, 'MA50/MA250': np.nan, 
            'MA50/MA250è¶‹åŠ¿': 'è®¡ç®—é”™è¯¯', 'å¸ƒæ—å¸¦ä½ç½®': 'è®¡ç®—é”™è¯¯',
            'æœ€æ–°å‡€å€¼': np.nan, 'å½“æ—¥è·Œå¹…': np.nan
        }

# --- è¿ç»­ä¸‹è·Œè®¡ç®— (å‡½æ•°é…ç½® 5/15) ---
def calculate_consecutive_drops(series):
    """è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°"""
    try:
        if series.empty or len(series) < 2: return 0
        # æ£€æŸ¥æœ€æ–°ä¸€å¤©æ˜¯å¦ä¸‹è·Œï¼ˆä¸å‰ä¸€å¤©ç›¸æ¯”ï¼‰ï¼Œä»¥ä¾¿è®¡ç®—å½“å‰çš„è¿è·Œå¤©æ•°
        drops = (series.diff() < 0).values
        current_drop_days = 0
        
        # ä»æœ€åä¸€å¤©å‘å‰è®¡ç®—å½“å‰çš„è¿ç»­ä¸‹è·Œå¤©æ•° (ä¸åŒ…æ‹¬ç¬¬ä¸€å¤©ï¼Œå› ä¸ºå®ƒæ˜¯ diff çš„ NaN)
        for is_dropped in reversed(drops[1:]):
            if is_dropped:
                current_drop_days += 1
            else:
                break # é‡åˆ°ä¸Šæ¶¨æˆ–å¹³ç›˜å³åœæ­¢
        
        return current_drop_days
    except Exception as e:
        logging.error(f"è®¡ç®—è¿ç»­ä¸‹è·Œå¤©æ•°æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0

# --- æœ€å¤§å›æ’¤è®¡ç®— (å‡½æ•°é…ç½® 6/15) ---
def calculate_max_drawdown(series):
    """è®¡ç®—æœ€å¤§å›æ’¤"""
    try:
        if series.empty: return 0.0
        rolling_max = series.cummax()
        drawdown = (rolling_max - series) / rolling_max
        return drawdown.max()
    except Exception as e:
        logging.error(f"è®¡ç®—æœ€å¤§å›æ’¤æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return 0.0

# --- å–å‡º/æ­¢æŸä¿¡å·ç”Ÿæˆ (å‡½æ•°é…ç½® 7/15) ---
def generate_exit_signal(row):
    """æ ¹æ® V5.0 æ­¢ç›ˆæ­¢æŸç­–ç•¥ï¼Œç”Ÿæˆé€€å‡º/æ­¢æŸæç¤º"""
    rsi_14_val = row.get('RSI(14)', np.nan)
    macd_signal = row.get('MACDä¿¡å·', '')
    mdd_recent_month = row.get('æœ€å¤§å›æ’¤', 0.0)
    
    exit_signals = []
    
    # 1. æ­¢ç›ˆä¿¡å·ï¼šRSI è¿‡ä¹°
    if not pd.isna(rsi_14_val) and rsi_14_val > 70.0:
        exit_signals.append("ğŸš« æ­¢ç›ˆï¼šRSI(14) è¿‡ä¹°")
        
    # 2. æ­¢ç›ˆ/æ­¢æŸä¿¡å·ï¼šMACD æ­»å‰
    if macd_signal == 'æ­»å‰': 
        exit_signals.append("ğŸš« æ­¢ç›ˆ/æ­¢æŸï¼šMACDæ­»å‰")
        
    # 3. æ­¢æŸä¿¡å·ï¼šè¿‘ä¸€æœˆå›æ’¤è¶…é™
    if mdd_recent_month > 0.10: 
        exit_signals.append(f"ğŸ›‘ æ­¢æŸï¼šå›æ’¤è¶… 10% ({mdd_recent_month:.2%})")
        
    if not exit_signals:
        return "æŒæœ‰"
        
    return ' | '.join(exit_signals)

# --- V5.0 è¡ŒåŠ¨ä¿¡å·ç”Ÿæˆ (å‡½æ•°é…ç½® 8/15) ---
def generate_v5_action_signal(row):
    """
    æ ¹æ® V5.0 ç­–ç•¥çš„æŠ€æœ¯è¦æ±‚ï¼Œç”Ÿæˆè¯•ä»“ä¿¡å·ã€‚
    """
    rsi_14_val = row.get('RSI(14)', np.nan)
    rsi_6_val = row.get('RSI(6)', np.nan)
    macd_signal = row.get('MACDä¿¡å·', '')
    bollinger_position = row.get('å¸ƒæ—å¸¦ä½ç½®', '')
    mdd_recent_month = row.get('æœ€å¤§å›æ’¤', 0.0)
    daily_drop_val = row.get('å½“æ—¥è·Œå¹…', 0.0)
    consecutive_drop_recent = row.get('è¿‘10æ—¥è¿è·Œ', 0) 
    
    signals = []

    # --- V5.0 ç½‘æ ¼çº§ / æå€¼è¶…å–ä¿¡å· ---
    if not pd.isna(rsi_14_val) and rsi_14_val <= EXTREME_RSI_THRESHOLD_P1:
        rsi_display = f"RSI14:{rsi_14_val:.1f}"
        if rsi_6_val <= SHORT_TERM_RSI_EXTREME:
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯({rsi_display})")
        elif daily_drop_val <= -MIN_DAILY_DROP_PERCENT:
            signals.append(f"ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼+ææ…Œ({rsi_display})")
        else:
            signals.append(f"ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼({rsi_display})")

    # --- V5.0 æ¸¸å‡»å§¿æ€ (éœ‡è¡å¸‚) ä¿¡å· ---
    if mdd_recent_month >= MIN_MONTH_DRAWDOWN:
        if consecutive_drop_recent >= 5:
             if not any('ç½‘æ ¼çº§' in s for s in signals):
                signals.append("âœ¨ã€éœ‡è¡-è¿è·Œã€‘è¿è·Œ5æ—¥+é«˜å›æ’¤") 
                
        if bollinger_position in ["**ä¸‹è½¨ä¸‹æ–¹**", "ä¸‹è½¨é™„è¿‘"]:
            signals.append("ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘è§¦åŠBOLLä¸‹è½¨")
        elif mdd_recent_month >= HIGH_ELASTICITY_MIN_DRAWDOWN:
            signals.append("ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘é«˜å¼¹æ€§å›æ’¤è¾¾æ ‡")
        elif not signals:
            signals.append("ã€éœ‡è¡-å…³æ³¨ã€‘åŸºç¡€å›æ’¤è¾¾æ ‡")

    # --- V5.0 é˜²å¾¡å§¿æ€ (ç†Šå¸‚) ä¿¡å· ---
    if macd_signal == 'å¼±åŠ¿é‡‘å‰':
        signals.append("ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘MACDå¼±é‡‘å‰")
        
    # --- V5.0 è¿›æ”»å§¿æ€ (ç‰›å¸‚) è¿‡æ»¤å™¨æ£€æŸ¥ ---
    if not pd.isna(rsi_14_val) and rsi_14_val > 70.0:
        signals.append("ğŸš«ã€ç‰›å¸‚è¿‡æ»¤å™¨ã€‘RSI(14)>70")
        
    if not signals:
        return 'ç­‰å¾…ä¿¡å· (æœªè¾¾åŸºç¡€å›æ’¤)'
        
    return ' | '.join(signals)

# --- éå†å¹¶åˆ†ææ‰€æœ‰åŸºé‡‘ (å‡½æ•°é…ç½® 9/15) ---
def analyze_all_funds():
    """éå† FUND_DATA_DIR ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶å¹¶åˆ†æ"""
    fund_files = glob.glob(os.path.join(FUND_DATA_DIR, '*.csv'))
    results = []
    
    if not fund_files:
        logging.warning(f"åœ¨ç›®å½• '{FUND_DATA_DIR}' ä¸­æœªæ‰¾åˆ°ä»»ä½•åŸºé‡‘æ•°æ®æ–‡ä»¶ã€‚")
        return results

    for filepath in fund_files:
        fund_result = analyze_single_fund(filepath)
        if fund_result:
            results.append(fund_result)
            
    logging.info(f"æ‰€æœ‰åŸºé‡‘åˆ†æå®Œæˆï¼Œå…± {len(results)} ä¸ªåŸºé‡‘ç¬¦åˆæŠ¥å‘Šæ¡ä»¶ã€‚")
    return results

# --- å•åŸºé‡‘åˆ†æ (å‡½æ•°é…ç½® 10/15) ---
def analyze_single_fund(filepath):
    """
    å•åŸºé‡‘åˆ†æï¼Œä½¿ç”¨æŠ½è±¡åçš„æ•°æ®åŠ è½½å‡½æ•°ã€‚
    """
    fund_code = os.path.splitext(os.path.basename(filepath))[0]
    
    # ä½¿ç”¨æŠ½è±¡å‡½æ•°åŠ è½½æ•°æ®
    df, msg = load_and_preprocess_data(filepath, fund_code)
    if df is None: 
        logging.warning(f"åŸºé‡‘ {fund_code} åˆ†æè·³è¿‡: {msg}")
        return None
        
    try:
        # åŠ¨æ€æ—¥æœŸçª—å£è®¡ç®—å›æ’¤
        latest_date = df['date'].iloc[-1]
        one_month_ago = latest_date - pd.DateOffset(months=1)
        df_recent_month = df[df['date'] >= one_month_ago]['value']
        
        if len(df_recent_month) < 2:
            mdd_recent_month = 0.0
        else:
            mdd_recent_month = calculate_max_drawdown(df_recent_month)
        
        tech_indicators = calculate_technical_indicators(df)
        
        # æ³¨æ„ï¼šè¿™é‡Œè®¡ç®—çš„ consecutive_drop_recent å·²ç»æ˜¯å½“å‰çš„è¿è·Œå¤©æ•°
        consecutive_drop_recent = calculate_consecutive_drops(df['value'].tail(10)) 

        row_data = {
            **tech_indicators, 
            'æœ€å¤§å›æ’¤': mdd_recent_month, 
            'å½“æ—¥è·Œå¹…': tech_indicators['å½“æ—¥è·Œå¹…'],
            'è¿‘10æ—¥è¿è·Œ': consecutive_drop_recent
        }
        
        action_prompt = generate_v5_action_signal(row_data)
        exit_prompt = generate_exit_signal(row_data)
        
        if not pd.isna(tech_indicators['æœ€æ–°å‡€å€¼']):
             return {
                 'åŸºé‡‘ä»£ç ': fund_code,
                 'æœ€å¤§å›æ’¤': mdd_recent_month,
                 'æœ€å¤§è¿ç»­ä¸‹è·Œ': calculate_consecutive_drops(df['value']),
                 'è¿‘10æ—¥è¿è·Œ': consecutive_drop_recent,
                 **tech_indicators,
                 'è¡ŒåŠ¨æç¤º': action_prompt,
                 'é€€å‡ºæç¤º': exit_prompt
             }
        return None
    except Exception as e:
        logging.error(f"åˆ†æåŸºé‡‘ {filepath} æ—¶å‘ç”Ÿæ•°æ®å¤„ç†é”™è¯¯: {e}")
        return None

# --- æŠ€æœ¯å€¼æ ¼å¼åŒ– (å‡½æ•°é…ç½® 11/15) ---
def format_technical_value(value, format_type='percent'):
    """æŠ€æœ¯å€¼æ ¼å¼åŒ–"""
    if pd.isna(value): return '---'
    
    if format_type == 'report_daily_drop':
        if value < 0:
            return f"**{value:.2%}**"
        elif value > 0:
            return f"{value:.2%}" 
        else:
            return "0.00%"
            
    if format_type == 'percent': return f"{value:.2%}"
    elif format_type == 'decimal2': return f"{value:.2f}"
    elif format_type == 'decimal4': return f"{value:.4f}"
    else: return str(value)

# --- è¡¨æ ¼è¡Œæ ¼å¼åŒ– (å‡½æ•°é…ç½® 12/15) ---
def format_table_row(index, row):
    """
    è¡¨æ ¼è¡Œæ ¼å¼åŒ– (ç²¾ç®€ç‰ˆ + å†²çªå¤„ç†)
    """
    latest_value = row.get('æœ€æ–°å‡€å€¼', 1.0)
    # è¯•æ°´ä¹°ä»· (è·Œ3%) è®¡ç®—ä¿æŒä¸å˜
    trial_price = latest_value * (1 - 0.03) 
    
    trend_display = row['MA50/MA250è¶‹åŠ¿']
    ma_ratio = row.get('MA50/MA250')
    ma_ratio_display = format_technical_value(ma_ratio, 'decimal2')
    
    is_data_insufficient = pd.isna(ma_ratio) or trend_display == 'æ•°æ®ä¸è¶³'
    
    # è¶‹åŠ¿é£é™©è­¦å‘Š
    if is_data_insufficient:
        trend_status = "---"
    elif trend_display == 'å‘ä¸‹' or (not pd.isna(ma_ratio) and ma_ratio < TREND_HEALTH_THRESHOLD): 
        trend_status = f"âš ï¸ **{trend_display}** ({ma_ratio_display})"
    else:
        trend_status = f"**{trend_display}** ({ma_ratio_display})"
        
    daily_drop_display = format_technical_value(row['å½“æ—¥è·Œå¹…'], 'report_daily_drop')
    
    # RSI(14) ä½¿ç”¨åŠ ç²—æ˜¾ç¤º
    rsi14_display = f"**{row['RSI(14)']:.2f}**" if not pd.isna(row['RSI(14)']) and row['RSI(14)'] <= STRONG_RSI_THRESHOLD_P2 else f"{row['RSI(14)']:.2f}"
    
    # *** æ ¸å¿ƒå†²çªå¤„ç†é€»è¾‘ ***
    v5_signal_content = row['è¡ŒåŠ¨æç¤º']
    exit_prompt = row['é€€å‡ºæç¤º']
    
    if "ğŸ›‘ æ­¢æŸï¼š" in exit_prompt:
        # å¦‚æœè§¦å‘äº†æ­¢æŸï¼Œåˆ™åœ¨ V5.0 ä¿¡å·å‰åŠ ä¸Šå¦å†³æç¤º
        v5_signal_display = f"ğŸš« **æ­¢æŸå¦å†³** | {v5_signal_content}"
    else:
        v5_signal_display = f"**{v5_signal_content}**"


    # *** å¯¹åº”ç²¾ç®€åçš„è¡¨å¤´è¾“å‡º ***
    return (
        f"| {index} | `{row['åŸºé‡‘ä»£ç ']}` | **{format_technical_value(row['æœ€å¤§å›æ’¤'], 'percent')}** | "
        f"{daily_drop_display} | {rsi14_display} | {v5_signal_display} | "
        f"**{exit_prompt}** | "
        f"{trend_status} | `{trial_price:.4f}` |\n"
    )

# --- æŠ¥å‘Šç”Ÿæˆ (å‡½æ•°é…ç½® 13/15) ---
def generate_report(results, timestamp_str):
    """ç”Ÿæˆå®Œæ•´çš„Markdownæ ¼å¼æŠ¥å‘Š"""
    try:
        if not results:
            return (f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                      f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°ä»»ä½•æœ‰æ•ˆçš„åŸºé‡‘æ•°æ®ã€‚**")

        df_results = pd.DataFrame(results)
        
        # è¿‡æ»¤å‡ºç¬¦åˆåŸºç¡€å›æ’¤æ¡ä»¶çš„åŸºé‡‘
        df_filtered = df_results[df_results['æœ€å¤§å›æ’¤'] >= MIN_MONTH_DRAWDOWN].copy()
        
        if df_filtered.empty:
            return (f"# åŸºé‡‘ V5.0 ç­–ç•¥é€‰è‚¡æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n"
                      f"**æ­å–œï¼Œæ²¡æœ‰å‘ç°æ»¡è¶³åŸºç¡€é¢„è­¦æ¡ä»¶ï¼ˆè¿‘ 1 ä¸ªæœˆå›æ’¤ $\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰çš„åŸºé‡‘ã€‚**")


        # 1. V5.0 ä¿¡å·åˆ†æ•° 
        df_filtered['signal_score'] = 0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼å…±æŒ¯'), 'signal_score'] = 5.0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ’¥ã€ç½‘æ ¼çº§ã€‘RSIæå€¼'), 'signal_score'] = 4.5
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸŒŸã€ç½‘æ ¼çº§ã€‘RSIæå€¼'), 'signal_score'] = 4.5
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ¯ã€éœ‡è¡-é«˜å¸ã€‘'), 'signal_score'] = 4.0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('âœ¨ã€éœ‡è¡-è¿è·Œã€‘'), 'signal_score'] = 3.5 
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ›¡ï¸ã€é˜²å¾¡-åå¼¹ã€‘'), 'signal_score'] = 3.0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ğŸ”¥ã€éœ‡è¡-é¢„è­¦ã€‘'), 'signal_score'] = 2.0
        df_filtered.loc[df_filtered['è¡ŒåŠ¨æç¤º'].str.contains('ã€éœ‡è¡-å…³æ³¨ã€‘'), 'signal_score'] = 1.0
        
        # 2. è¶‹åŠ¿è¿‡æ»¤å™¨ 
        def get_trend_score(row):
            trend = row['MA50/MA250è¶‹åŠ¿']
            ratio = row['MA50/MA250']
            
            if pd.isna(ratio) or trend == 'æ•°æ®ä¸è¶³':
                return 50 
                
            if trend == 'å‘ä¸‹' or ratio < TREND_HEALTH_THRESHOLD: 
                return 0 # æ‹’ç»ä¹°å…¥
            
            return 100 

        df_filtered['trend_score'] = df_filtered.apply(get_trend_score, axis=1)

        # 3. V5.0 ç»¼åˆè¯„åˆ† 
        df_filtered['final_score'] = df_filtered['signal_score'] * (df_filtered['trend_score'] / 100) * 1000 + (df_filtered['æœ€å¤§å›æ’¤'] * 100)
        
        # *** æ–°å¢æ­¢æŸå¦å†³æ ‡å¿— ***
        # 0 = æœªè§¦å‘æ­¢æŸ (å¯ä¹°å…¥)ï¼›1 = è§¦å‘æ­¢æŸ (å¦å†³ä¹°å…¥)
        df_filtered['is_stop_loss'] = np.where(df_filtered['æœ€å¤§å›æ’¤'] > 0.10, 1, 0)
        # ------------------------------------
        
        # 4. åˆ†ç»„
        # ä»…ä¿ç•™é€šè¿‡è¶‹åŠ¿å¥åº·åº¦ä¸”ä¿¡å·å¼ºåº¦è¾¾æ ‡çš„åŸºé‡‘
        df_buy = df_filtered[(df_filtered['trend_score'] == 100) & (df_filtered['signal_score'] >= MIN_BUY_SIGNAL_SCORE)].copy()
        df_reject_trend = df_filtered[df_filtered['trend_score'] == 0].copy()
        
        
        # 5. æŠ¥å‘Šæ’åº (æ ¸å¿ƒä¿®æ”¹: ä¼˜å…ˆæœªæ­¢æŸï¼Œç„¶åæŒ‰ä¿¡å·åˆ†å’Œå›æ’¤æ’åº)
        df_buy_sorted = df_buy.sort_values(
            by=['is_stop_loss', 'signal_score', 'æœ€å¤§å›æ’¤'], 
            ascending=[True, False, False] # True: 0æ’åœ¨å‰é¢ï¼ˆæœªæ­¢æŸï¼‰ï¼›False: é«˜åˆ†é«˜å›æ’¤æ’åœ¨å‰é¢
        )
        
        # FIX: å¯¹è¶‹åŠ¿ä¸å¥åº·çš„åŸºé‡‘è¿›è¡Œæ’åº
        df_reject_trend_sorted = df_reject_trend.sort_values(
            by=['æœ€å¤§å›æ’¤', 'signal_score'],
            ascending=[False, False]
        )
        
        
        # 6. é‡æ–°åˆ†ç»„åˆ° I.1 (å¯ä¹°) å’Œ I.2 (æ­¢æŸå¦å†³) ç»„
        df_i_buyable = df_buy_sorted[df_buy_sorted['is_stop_loss'] == 0] # çœŸæ­£å¯ä¹°å…¥çš„ç›®æ ‡
        df_ii_rejected_stoploss = df_buy_sorted[df_buy_sorted['is_stop_loss'] == 1] # è¶‹åŠ¿å¥åº·ä½†è¢«æ­¢æŸå¦å†³çš„ç›®æ ‡
        
        
        report_parts = []
        report_parts.extend([
            f"# åŸºé‡‘ V5.0 ç­–ç•¥é€‰è‚¡æŠ¥å‘Š ({timestamp_str} UTC+8)\n\n",
            f"## åˆ†ææ€»ç»“\n\n",
            f"æœ¬æ¬¡åˆ†æå…±å‘ç° **{len(df_filtered)}** åªåŸºé‡‘æ»¡è¶³åŸºç¡€å›æ’¤æ¡ä»¶ï¼ˆ$\\ge {MIN_MONTH_DRAWDOWN*100:.0f}\\%$ï¼‰ã€‚\n",
            f"å…¶ä¸­ï¼Œ**{len(df_i_buyable)}** åªåŸºé‡‘åŒæ—¶æ»¡è¶³ **è¶‹åŠ¿å¥åº·ã€æœ€ä½ä¿¡å·å¼ºåº¦** å’Œ **æœªè§¦å‘æ­¢æŸ**ï¼Œè¢«åˆ—ä¸º**æœ€é«˜ä¼˜å…ˆçº§è¯•ä»“ç›®æ ‡**ã€‚\n",
            f"**å†³ç­–é‡ç‚¹ï¼š** **è¯·ä¼˜å…ˆä» ğŸ¥‡ I.1 ç»„é€‰æ‹©æ ‡çš„ã€‚**\n",
            f"\n---\n"
        ])
        
        
        # A. ã€æœ€é«˜ä¼˜å…ˆçº§å¯è¯•ä»“ã€‘ -> I.1
        if not df_i_buyable.empty:
            report_parts.extend([
                f"\n## ğŸ¥‡ I.1 ã€æœ€é«˜ä¼˜å…ˆçº§/å¯è¯•ä»“ç›®æ ‡ã€‘ ({len(df_i_buyable)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¶‹åŠ¿å¥åº·ä¸”å…·æœ‰å¼ºä¿¡å·ï¼Œ**æœªè§¦å‘æ­¢æŸçºªå¾‹**ã€‚è¿™æ˜¯**å”¯ä¸€å…è®¸è¯•ä»“**çš„æ ‡çš„æ± ã€‚\n\n"
            ])
            report_parts.append(generate_merged_table(df_i_buyable))

        
        # B. ã€è¶‹åŠ¿å¥åº·ä½†æ­¢æŸå¦å†³ã€‘ -> I.2
        if not df_ii_rejected_stoploss.empty:
            report_parts.extend([
                f"\n## ğŸš« I.2 ã€è¶‹åŠ¿å¥åº·ä½†æ­¢æŸå¦å†³ã€‘ ({len(df_ii_rejected_stoploss)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¶‹åŠ¿å¥åº·ä¸”å‡ºç°ä¹°å…¥ä¿¡å·ï¼Œä½†**å·²è§¦å‘æ­¢æŸçºªå¾‹ï¼ˆå›æ’¤ $> 10\%$ï¼‰**ã€‚ä¸åº”å†æŠ•å…¥èµ„é‡‘ã€‚\n\n"
            ])
            report_parts.append(generate_merged_table(df_ii_rejected_stoploss))
        
        # C. ã€è¶‹åŠ¿ä¸å¥åº·/å¿…é¡»æ”¾å¼ƒã€‘ -> IV. 
        if not df_reject_trend_sorted.empty:
            report_parts.extend([
                f"\n## âŒ IV. ã€è¶‹åŠ¿ä¸å¥åº·/å¿…é¡»æ”¾å¼ƒã€‘ ({len(df_reject_trend_sorted)}åª)\n\n",
                f"**çºªå¾‹ï¼š** è¿™äº›åŸºé‡‘**æœªé€šè¿‡è¶‹åŠ¿å¥åº·åº¦å®¡æ ¸**ï¼ˆMA50/MA250 $< {TREND_HEALTH_THRESHOLD:.1f}$ æˆ– è¶‹åŠ¿å‘ä¸‹ï¼‰ã€‚**é£é™©è¿‡é«˜ï¼Œè¯·æ”¾å¼ƒè¯•ä»“ã€‚**\n\n"
            ])
            report_parts.append(generate_merged_table(df_reject_trend_sorted))


        # ç­–ç•¥æ‰§è¡Œçºªå¾‹ (ç²¾ç®€ç‰ˆ)
        report_parts.extend([
            "\n---\n",
            f"## **âœ… æ ¸å¿ƒå†³ç­–çºªå¾‹æ€»ç»“**\n\n",
            f"**1. ğŸ† ä¼˜å…ˆçº§ï¼š** ä¼˜å…ˆä» ğŸ¥‡ I.1 ç»„é€‰å–ç›®æ ‡ï¼Œ**é€€å‡ºæç¤º**å…·æœ‰æœ€é«˜å†³ç­–ä¼˜å…ˆçº§ã€‚\n",
            f"**2. ğŸ›‘ è¶‹åŠ¿å¥åº·åº¦ï¼š** è‹¥ MA50/MA250 $< {TREND_HEALTH_THRESHOLD:.1f}$ æˆ–è¶‹åŠ¿å‘ä¸‹ï¼Œ**å¿…é¡»æ”¾å¼ƒè¯•ä»“**ã€‚\n",
            f"**3. ğŸ’° ä»“ä½çºªå¾‹ï¼š** è¯·æ‰‹åŠ¨åˆ¤æ–­å®è§‚ç¯å¢ƒï¼ˆç‰›å¸‚/éœ‡è¡å¸‚/ç†Šå¸‚ï¼‰ï¼Œå¹¶æ®æ­¤ç¡®å®šæœ¬æ¬¡è¯•ä»“ä»“ä½ï¼ˆ5%, 10%, 20%ï¼‰ã€‚\n"
        ])

        return "".join(report_parts)
        
    except Exception as e:
        logging.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"# æŠ¥å‘Šç”Ÿæˆé”™è¯¯\n\né”™è¯¯ä¿¡æ¯: {str(e)}"

# --- è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆåˆå¹¶åçš„è¡¨æ ¼ (å‡½æ•°é…ç½® 14/15) ---
def generate_merged_table(df_group):
    """ç”ŸæˆæŠ¥å‘Šä¸­çš„Markdownè¡¨æ ¼ (ç²¾ç®€ç‰ˆ)"""
    
    # *** ç®€åŒ–åçš„æ–°è¡¨å¤´ (9åˆ—) ***
    FULL_HEADER = (
        f"| æ’å | åŸºé‡‘ä»£ç  | **æœ€å¤§å›æ’¤ (1M)** | **å½“æ—¥è·Œå¹…** | RSI(14) | **V5.0 ä¿¡å·** | "
        f"**é€€å‡ºæç¤º** | MA50/MA250å¥åº·åº¦ | è¯•æ°´ä¹°ä»· (è·Œ3%) |\n"
    )
    FULL_SEPARATOR = f"| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |\n" 
    
    parts = []
    
    parts.extend([
        "### ç»¼åˆæŠ€æœ¯åˆ†æè¡¨\n",
        FULL_HEADER,
        FULL_SEPARATOR
    ])

    current_index = 0
    for _, row in df_group.iterrows():
        current_index += 1
        parts.append(format_table_row(current_index, row)) 
        
    parts.append("\n---\n")
    return "".join(parts)

# --- ä¸»å‡½æ•° (å‡½æ•°é…ç½® 15/15) ---
def main():
    """ä¸»å‡½æ•°"""
    try:
        setup_logging()
        try:
            tz = pytz.timezone('Asia/Shanghai')
            now = datetime.now(tz)
        except Exception:
            now = datetime.now()
            logging.warning("ä½¿ç”¨æ—¶åŒºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—¶é—´")
            
        timestamp_for_report = now.strftime('%Y-%m-%d %H:%M:%S')
        timestamp_for_filename = now.strftime('%Y%m%d_%H%M%S')
        dir_name = now.strftime('%Y%m')

        os.makedirs(dir_name, exist_ok=True)
        report_file = os.path.join(dir_name, f"{REPORT_BASE_NAME}_{timestamp_for_filename}.md")

        logging.info("å¼€å§‹åˆ†æåŸºé‡‘æ•°æ®...")
        
        if not os.path.isdir(FUND_DATA_DIR):
            logging.error(f"åŸºé‡‘æ•°æ®ç›®å½• '{FUND_DATA_DIR}' ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºè¯¥ç›®å½•å¹¶æ”¾å…¥ CSV æ–‡ä»¶ã€‚")
            # å³ä½¿ç›®å½•ä¸å­˜åœ¨ï¼Œä¹Ÿç”Ÿæˆä¸€ä¸ªç©ºçš„æŠ¥å‘Š
            with open(report_file, 'w', encoding='utf-8') as f:
                 f.write(f"# åŸºé‡‘é¢„è­¦æŠ¥å‘Š ({timestamp_for_report} UTC+8)\n\n**é”™è¯¯ï¼š** åŸºé‡‘æ•°æ®ç›®å½• `fund_data` ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
            return False

        results = analyze_all_funds()
        
        report_content = generate_report(results, timestamp_for_report)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜åˆ° {report_file}")
        return True
        
    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    # ç¡®ä¿ fund_data ç›®å½•å­˜åœ¨
    if not os.path.isdir('fund_data'):
        os.makedirs('fund_data', exist_ok=True)
        
    success = main()
    if success:
        print(f"è„šæœ¬æ‰§è¡Œå®Œæ¯•ã€‚V5.0 ç­–ç•¥æŠ¥å‘Šå·²æ›´æ–°ï¼Œæ‚¨çš„ **å¯ä¹°å…¥ç›®æ ‡** ç°åœ¨ä¼šæ’åœ¨æŠ¥å‘Šæœ€å‰é¢ï¼ˆğŸ¥‡ I.1 ç»„ï¼‰ã€‚")
    else:
        print("è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥ fund_analysis.log æ–‡ä»¶ä»¥è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚")
